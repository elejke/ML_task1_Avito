{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data  # we take all features.\n",
    "#X = iris.data[:, :2]  # we only take the first two features.\n",
    "Y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем ответы (отделять будем setosa (метка класса 0) от остального):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in xrange(len(Y)):\n",
    "    if Y[i] == 0:\n",
    "        Y[i] = 1\n",
    "    else:\n",
    "        Y[i] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиваем данные на две части: одна для обучения, другая для тестирования:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функции для вычисления loss, которую и будем оптимизировать, (ее можно менять, я пробовал несколько вариантов, но для примера оставил сигмоиду) и ее производной, а также непосредственно классификатор:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def L(t):\n",
    "    #return np.e**(-t)\n",
    "    #return (1-t)**2\n",
    "    return 2/(1+np.e**t)\n",
    "\n",
    "def L_derivative(t):\n",
    "    #return -np.e**(-t)\n",
    "    #return 2*(t-1)\n",
    "    return -2*np.e**t/((1+np.e**t)**2)\n",
    "    \n",
    "class StochGrad:\n",
    "    def __init__(self, learning_rate, smooth_parameter):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.smooth_parameter = smooth_parameter\n",
    "        \n",
    "    w = np.zeros([1,1])\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        \n",
    "        n = len(X)\n",
    "        d = len(X[0])\n",
    "        X = np.hstack([X, -np.ones([n,1])])\n",
    "        \n",
    "        self.w = np.random.uniform(-0.5/d, 0.5/d, d+1)\n",
    "        Q = 0\n",
    "        for i in xrange(n):\n",
    "            Q += L(np.dot(self.w, X[i])*Y[i])\n",
    "        convergence = False\n",
    "        \n",
    "        iterations = 0\n",
    "        while (not convergence):\n",
    "            print self.w\n",
    "            print Q\n",
    "            w_last = self.w\n",
    "            Q_last = Q\n",
    "            \n",
    "            i = np.random.randint(n)\n",
    "            eps = L(np.dot(self.w, X[i])*Y[i])\n",
    "            self.w = self.w - self.learning_rate*L_derivative(np.dot(self.w, X[i])*Y[i])*Y[i]*X[i]\n",
    "            print L_derivative(np.dot(self.w, X[i])*Y[i])\n",
    "            Q = (1-self.smooth_parameter)*Q + self.smooth_parameter*eps\n",
    "            \n",
    "            if (abs((Q-Q_last)/Q) < 0.01):\n",
    "                convergence = True\n",
    "            iterations += 1\n",
    "            \n",
    "    def predict(self, X):\n",
    "        \n",
    "        n = len(X)\n",
    "        X = np.hstack([X, -np.ones([n,1])])\n",
    "        Y = np.zeros(n)\n",
    "        \n",
    "        for i in xrange(n):\n",
    "            Y[i] = np.sign(np.dot(self.w, X[i]))\n",
    "            \n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.11398209 -0.04714994  0.09467651  0.05046343 -0.00027587]\n",
      "159.551257499\n",
      "-0.232412424169\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True, False, False, False,  True, False, False,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False, False,  True,  True,  True], dtype=bool)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = StochGrad(0.1, 1.0/150)\n",
    "clf.fit(X_train, Y_train)\n",
    "Y_pred = clf.predict(X_test)\n",
    "Y_pred == Y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39130434782608692"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "metrics.zero_one_loss(Y_test,Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как-то странно и бредово работает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
