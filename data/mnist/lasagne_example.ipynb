{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 980\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "\"\"\"\n",
    "Usage example employing Lasagne for digit recognition using the MNIST dataset.\n",
    "This example is deliberately structured as a long flat file, focusing on how\n",
    "to use Lasagne, instead of focusing on writing maximally modular and reusable\n",
    "code. It is used as the foundation for the introductory Lasagne tutorial:\n",
    "http://lasagne.readthedocs.org/en/latest/user/tutorial.html\n",
    "More in-depth examples and reproductions of paper results are maintained in\n",
    "a separate repository: https://github.com/Lasagne/Recipes\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "import lasagne\n",
    "\n",
    "\n",
    "# ################## Download and prepare the MNIST dataset ##################\n",
    "# This is just some way of getting the MNIST dataset from an online location\n",
    "# and loading it into numpy arrays. It doesn't involve Lasagne at all.\n",
    "\n",
    "def load_dataset():\n",
    "    # We first define a download function, supporting both Python 2 and 3.\n",
    "    if sys.version_info[0] == 2:\n",
    "        from urllib import urlretrieve\n",
    "    else:\n",
    "        from urllib.request import urlretrieve\n",
    "\n",
    "    def download(filename, source='http://yann.lecun.com/exdb/mnist/'):\n",
    "        print(\"Downloading %s\" % filename)\n",
    "        urlretrieve(source + filename, filename)\n",
    "\n",
    "    # We then define functions for loading MNIST images and labels.\n",
    "    # For convenience, they also download the requested files if needed.\n",
    "    import gzip\n",
    "\n",
    "    def load_mnist_images(filename):\n",
    "        if not os.path.exists(filename):\n",
    "            download(filename)\n",
    "        # Read the inputs in Yann LeCun's binary format.\n",
    "        with gzip.open(filename, 'rb') as f:\n",
    "            data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "        # The inputs are vectors now, we reshape them to monochrome 2D images,\n",
    "        # following the shape convention: (examples, channels, rows, columns)\n",
    "        data = data.reshape(-1, 1, 28, 28)\n",
    "        # The inputs come as bytes, we convert them to float32 in range [0,1].\n",
    "        # (Actually to range [0, 255/256], for compatibility to the version\n",
    "        # provided at http://deeplearning.net/data/mnist/mnist.pkl.gz.)\n",
    "        return data / np.float32(256)\n",
    "\n",
    "    def load_mnist_labels(filename):\n",
    "        if not os.path.exists(filename):\n",
    "            download(filename)\n",
    "        # Read the labels in Yann LeCun's binary format.\n",
    "        with gzip.open(filename, 'rb') as f:\n",
    "            data = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "        # The labels are vectors of integers now, that's exactly what we want.\n",
    "        return data\n",
    "\n",
    "    # We can now download and read the training and test set images and labels.\n",
    "    X_train = load_mnist_images('train-images-idx3-ubyte.gz')\n",
    "    y_train = load_mnist_labels('train-labels-idx1-ubyte.gz')\n",
    "    X_test = load_mnist_images('t10k-images-idx3-ubyte.gz')\n",
    "    y_test = load_mnist_labels('t10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "    # We reserve the last 10000 training examples for validation.\n",
    "    X_train, X_val = X_train[:-10000], X_train[-10000:]\n",
    "    y_train, y_val = y_train[:-10000], y_train[-10000:]\n",
    "\n",
    "    # We just return all the arrays in order, as expected in main().\n",
    "    # (It doesn't matter how we do this as long as we can read them again.)\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "\n",
    "# ##################### Build the neural network model #######################\n",
    "# This script supports three types of models. For each one, we define a\n",
    "# function that takes a Theano variable representing the input and returns\n",
    "# the output layer of a neural network model built in Lasagne.\n",
    "\n",
    "def build_mlp(input_var=None):\n",
    "    # This creates an MLP of two hidden layers of 800 units each, followed by\n",
    "    # a softmax output layer of 10 units. It applies 20% dropout to the input\n",
    "    # data and 50% dropout to the hidden layers.\n",
    "\n",
    "    # Input layer, specifying the expected input shape of the network\n",
    "    # (unspecified batchsize, 1 channel, 28 rows and 28 columns) and\n",
    "    # linking it to the given Theano variable `input_var`, if any:\n",
    "    l_in = lasagne.layers.InputLayer(shape=(None, 1, 28, 28),\n",
    "                                     input_var=input_var)\n",
    "\n",
    "    # Apply 20% dropout to the input data:\n",
    "    l_in_drop = lasagne.layers.DropoutLayer(l_in, p=0.2)\n",
    "\n",
    "    # Add a fully-connected layer of 800 units, using the linear rectifier, and\n",
    "    # initializing weights with Glorot's scheme (which is the default anyway):\n",
    "    l_hid1 = lasagne.layers.DenseLayer(\n",
    "            l_in_drop, num_units=800,\n",
    "            nonlinearity=lasagne.nonlinearities.rectify,\n",
    "            W=lasagne.init.GlorotUniform())\n",
    "\n",
    "    # We'll now add dropout of 50%:\n",
    "    l_hid1_drop = lasagne.layers.DropoutLayer(l_hid1, p=0.5)\n",
    "\n",
    "    # Another 800-unit layer:\n",
    "    l_hid2 = lasagne.layers.DenseLayer(\n",
    "            l_hid1_drop, num_units=800,\n",
    "            nonlinearity=lasagne.nonlinearities.rectify)\n",
    "\n",
    "    # 50% dropout again:\n",
    "    l_hid2_drop = lasagne.layers.DropoutLayer(l_hid2, p=0.5)\n",
    "\n",
    "    # Finally, we'll add the fully-connected output layer, of 10 softmax units:\n",
    "    l_out = lasagne.layers.DenseLayer(\n",
    "            l_hid2_drop, num_units=10,\n",
    "            nonlinearity=lasagne.nonlinearities.softmax)\n",
    "\n",
    "    # Each layer is linked to its incoming layer(s), so we only need to pass\n",
    "    # the output layer to give access to a network in Lasagne:\n",
    "    return l_out\n",
    "\n",
    "\n",
    "def build_custom_mlp(input_var=None, depth=2, width=800, drop_input=.2,\n",
    "                     drop_hidden=.5):\n",
    "    # By default, this creates the same network as `build_mlp`, but it can be\n",
    "    # customized with respect to the number and size of hidden layers. This\n",
    "    # mostly showcases how creating a network in Python code can be a lot more\n",
    "    # flexible than a configuration file. Note that to make the code easier,\n",
    "    # all the layers are just called `network` -- there is no need to give them\n",
    "    # different names if all we return is the last one we created anyway; we\n",
    "    # just used different names above for clarity.\n",
    "\n",
    "    # Input layer and dropout (with shortcut `dropout` for `DropoutLayer`):\n",
    "    network = lasagne.layers.InputLayer(shape=(None, 1, 28, 28),\n",
    "                                        input_var=input_var)\n",
    "    if drop_input:\n",
    "        network = lasagne.layers.dropout(network, p=drop_input)\n",
    "    # Hidden layers and dropout:\n",
    "    nonlin = lasagne.nonlinearities.rectify\n",
    "    for _ in range(depth):\n",
    "        network = lasagne.layers.DenseLayer(\n",
    "                network, width, nonlinearity=nonlin)\n",
    "        if drop_hidden:\n",
    "            network = lasagne.layers.dropout(network, p=drop_hidden)\n",
    "    # Output layer:\n",
    "    softmax = lasagne.nonlinearities.softmax\n",
    "    network = lasagne.layers.DenseLayer(network, 10, nonlinearity=softmax)\n",
    "    return network\n",
    "\n",
    "\n",
    "def build_cnn(input_var=None):\n",
    "    # As a third model, we'll create a CNN of two convolution + pooling stages\n",
    "    # and a fully-connected hidden layer in front of the output layer.\n",
    "\n",
    "    # Input layer, as usual:\n",
    "    network = lasagne.layers.InputLayer(shape=(None, 1, 28, 28),\n",
    "                                        input_var=input_var)\n",
    "    # This time we do not apply input dropout, as it tends to work less well\n",
    "    # for convolutional layers.\n",
    "\n",
    "    # Convolutional layer with 32 kernels of size 5x5. Strided and padded\n",
    "    # convolutions are supported as well; see the docstring.\n",
    "    network = lasagne.layers.Conv2DLayer(\n",
    "            network, num_filters=32, filter_size=(5, 5),\n",
    "            nonlinearity=lasagne.nonlinearities.rectify,\n",
    "            W=lasagne.init.GlorotUniform())\n",
    "    # Expert note: Lasagne provides alternative convolutional layers that\n",
    "    # override Theano's choice of which implementation to use; for details\n",
    "    # please see http://lasagne.readthedocs.org/en/latest/user/tutorial.html.\n",
    "\n",
    "    # Max-pooling layer of factor 2 in both dimensions:\n",
    "    network = lasagne.layers.MaxPool2DLayer(network, pool_size=(2, 2))\n",
    "\n",
    "    # Another convolution with 32 5x5 kernels, and another 2x2 pooling:\n",
    "    network = lasagne.layers.Conv2DLayer(\n",
    "            network, num_filters=32, filter_size=(5, 5),\n",
    "            nonlinearity=lasagne.nonlinearities.rectify)\n",
    "    network = lasagne.layers.MaxPool2DLayer(network, pool_size=(2, 2))\n",
    "\n",
    "    # A fully-connected layer of 256 units with 50% dropout on its inputs:\n",
    "    network = lasagne.layers.DenseLayer(\n",
    "            lasagne.layers.dropout(network, p=.5),\n",
    "            num_units=256,\n",
    "            nonlinearity=lasagne.nonlinearities.rectify)\n",
    "\n",
    "    # And, finally, the 10-unit output layer with 50% dropout on its inputs:\n",
    "    network = lasagne.layers.DenseLayer(\n",
    "            lasagne.layers.dropout(network, p=.5),\n",
    "            num_units=10,\n",
    "            nonlinearity=lasagne.nonlinearities.softmax)\n",
    "\n",
    "    return network\n",
    "\n",
    "\n",
    "# ############################# Batch iterator ###############################\n",
    "# This is just a simple helper function iterating over training data in\n",
    "# mini-batches of a particular size, optionally in random order. It assumes\n",
    "# data is available as numpy arrays. For big datasets, you could load numpy\n",
    "# arrays as memory-mapped files (np.load(..., mmap_mode='r')), or write your\n",
    "# own custom data iteration function. For small datasets, you can also copy\n",
    "# them to GPU at once for slightly improved performance. This would involve\n",
    "# several changes in the main program, though, and is not demonstrated here.\n",
    "\n",
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]\n",
    "\n",
    "\n",
    "# ############################## Main program ################################\n",
    "# Everything else will be handled in our main program now. We could pull out\n",
    "# more functions to better separate the code, but it wouldn't make it any\n",
    "# easier to read.\n",
    "\n",
    "def main(model='mlp', num_epochs=500):\n",
    "    # Load the dataset\n",
    "    print(\"Loading data...\")\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = load_dataset()\n",
    "\n",
    "    # Prepare Theano variables for inputs and targets\n",
    "    input_var = T.tensor4('inputs')\n",
    "    target_var = T.ivector('targets')\n",
    "\n",
    "    # Create neural network model (depending on first command line parameter)\n",
    "    print(\"Building model and compiling functions...\")\n",
    "    if model == 'mlp':\n",
    "        network = build_mlp(input_var)\n",
    "    elif model.startswith('custom_mlp:'):\n",
    "        depth, width, drop_in, drop_hid = model.split(':', 1)[1].split(',')\n",
    "        network = build_custom_mlp(input_var, int(depth), int(width),\n",
    "                                   float(drop_in), float(drop_hid))\n",
    "    elif model == 'cnn':\n",
    "        network = build_cnn(input_var)\n",
    "    else:\n",
    "        print(\"Unrecognized model type %r.\" % model)\n",
    "        return\n",
    "\n",
    "    # Create a loss expression for training, i.e., a scalar objective we want\n",
    "    # to minimize (for our multi-class problem, it is the cross-entropy loss):\n",
    "    prediction = lasagne.layers.get_output(network)\n",
    "    loss = lasagne.objectives.categorical_crossentropy(prediction, target_var)\n",
    "    loss = loss.mean()\n",
    "    # We could add some weight decay as well here, see lasagne.regularization.\n",
    "\n",
    "    # Create update expressions for training, i.e., how to modify the\n",
    "    # parameters at each training step. Here, we'll use Stochastic Gradient\n",
    "    # Descent (SGD) with Nesterov momentum, but Lasagne offers plenty more.\n",
    "    params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "    updates = lasagne.updates.nesterov_momentum(\n",
    "            loss, params, learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "    # Create a loss expression for validation/testing. The crucial difference\n",
    "    # here is that we do a deterministic forward pass through the network,\n",
    "    # disabling dropout layers.\n",
    "    test_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "    test_loss = lasagne.objectives.categorical_crossentropy(test_prediction,\n",
    "                                                            target_var)\n",
    "    test_loss = test_loss.mean()\n",
    "    # As a bonus, also create an expression for the classification accuracy:\n",
    "    test_acc = T.mean(T.eq(T.argmax(test_prediction, axis=1), target_var),\n",
    "                      dtype=theano.config.floatX)\n",
    "\n",
    "    # Compile a function performing a training step on a mini-batch (by giving\n",
    "    # the updates dictionary) and returning the corresponding training loss:\n",
    "    train_fn = theano.function([input_var, target_var], loss, updates=updates)\n",
    "\n",
    "    # Compile a second function computing the validation loss and accuracy:\n",
    "    val_fn = theano.function([input_var, target_var], [test_loss, test_acc])\n",
    "\n",
    "    # Finally, launch the training loop.\n",
    "    print(\"Starting training...\")\n",
    "    # We iterate over epochs:\n",
    "    for epoch in range(num_epochs):\n",
    "        # In each epoch, we do a full pass over the training data:\n",
    "        train_err = 0\n",
    "        train_batches = 0\n",
    "        start_time = time.time()\n",
    "        for batch in iterate_minibatches(X_train, y_train, 500, shuffle=True):\n",
    "            inputs, targets = batch\n",
    "            train_err += train_fn(inputs, targets)\n",
    "            train_batches += 1\n",
    "\n",
    "        # And a full pass over the validation data:\n",
    "        val_err = 0\n",
    "        val_acc = 0\n",
    "        val_batches = 0\n",
    "        for batch in iterate_minibatches(X_val, y_val, 500, shuffle=False):\n",
    "            inputs, targets = batch\n",
    "            err, acc = val_fn(inputs, targets)\n",
    "            val_err += err\n",
    "            val_acc += acc\n",
    "            val_batches += 1\n",
    "\n",
    "        # Then we print the results for this epoch:\n",
    "        print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "            epoch + 1, num_epochs, time.time() - start_time))\n",
    "        print(\"  training loss:\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "        print(\"  validation loss:\\t\\t{:.6f}\".format(val_err / val_batches))\n",
    "        print(\"  validation accuracy:\\t\\t{:.2f} %\".format(\n",
    "            val_acc / val_batches * 100))\n",
    "\n",
    "    # After training, we compute and print the test error:\n",
    "    test_err = 0\n",
    "    test_acc = 0\n",
    "    test_batches = 0\n",
    "    for batch in iterate_minibatches(X_test, y_test, 500, shuffle=False):\n",
    "        inputs, targets = batch\n",
    "        err, acc = val_fn(inputs, targets)\n",
    "        test_err += err\n",
    "        test_acc += acc\n",
    "        test_batches += 1\n",
    "    print(\"Final results:\")\n",
    "    print(\"  test loss:\\t\\t\\t{:.6f}\".format(test_err / test_batches))\n",
    "    print(\"  test accuracy:\\t\\t{:.2f} %\".format(\n",
    "        test_acc / test_batches * 100))\n",
    "\n",
    "    # Optionally, you could now dump the network weights to a file like this:\n",
    "    # np.savez('model.npz', *lasagne.layers.get_all_param_values(network))\n",
    "    #\n",
    "    # And load them again later on like this:\n",
    "    # with np.load('model.npz') as f:\n",
    "    #     param_values = [f['arr_%d' % i] for i in range(len(f.files))]\n",
    "    # lasagne.layers.set_all_param_values(network, param_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fbd6d4018d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nED8QaCCC+IFAAxHEDwQaiP8PYrfpjRk/ZYUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbd6d556190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pylab as plt\n",
    "\n",
    "plt.imshow(X_train[0].reshape(28,28),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Building model and compiling functions...\n",
      "Starting training...\n",
      "Epoch 1 of 500 took 1.335s\n",
      "  training loss:\t\t1.248632\n",
      "  validation loss:\t\t0.418840\n",
      "  validation accuracy:\t\t88.05 %\n",
      "Epoch 2 of 500 took 1.298s\n",
      "  training loss:\t\t0.570568\n",
      "  validation loss:\t\t0.308021\n",
      "  validation accuracy:\t\t91.28 %\n",
      "Epoch 3 of 500 took 1.330s\n",
      "  training loss:\t\t0.470071\n",
      "  validation loss:\t\t0.264083\n",
      "  validation accuracy:\t\t92.45 %\n",
      "Epoch 4 of 500 took 1.327s\n",
      "  training loss:\t\t0.419380\n",
      "  validation loss:\t\t0.235541\n",
      "  validation accuracy:\t\t93.06 %\n",
      "Epoch 5 of 500 took 1.309s\n",
      "  training loss:\t\t0.374315\n",
      "  validation loss:\t\t0.213803\n",
      "  validation accuracy:\t\t93.65 %\n",
      "Epoch 6 of 500 took 1.323s\n",
      "  training loss:\t\t0.346022\n",
      "  validation loss:\t\t0.198422\n",
      "  validation accuracy:\t\t94.16 %\n",
      "Epoch 7 of 500 took 1.321s\n",
      "  training loss:\t\t0.319444\n",
      "  validation loss:\t\t0.181928\n",
      "  validation accuracy:\t\t94.71 %\n",
      "Epoch 8 of 500 took 1.442s\n",
      "  training loss:\t\t0.303070\n",
      "  validation loss:\t\t0.170790\n",
      "  validation accuracy:\t\t95.06 %\n",
      "Epoch 9 of 500 took 1.310s\n",
      "  training loss:\t\t0.280687\n",
      "  validation loss:\t\t0.160192\n",
      "  validation accuracy:\t\t95.39 %\n",
      "Epoch 10 of 500 took 1.353s\n",
      "  training loss:\t\t0.268867\n",
      "  validation loss:\t\t0.149937\n",
      "  validation accuracy:\t\t95.88 %\n",
      "Epoch 11 of 500 took 1.314s\n",
      "  training loss:\t\t0.253850\n",
      "  validation loss:\t\t0.142762\n",
      "  validation accuracy:\t\t95.98 %\n",
      "Epoch 12 of 500 took 1.309s\n",
      "  training loss:\t\t0.242481\n",
      "  validation loss:\t\t0.136356\n",
      "  validation accuracy:\t\t96.22 %\n",
      "Epoch 13 of 500 took 1.286s\n",
      "  training loss:\t\t0.235280\n",
      "  validation loss:\t\t0.130330\n",
      "  validation accuracy:\t\t96.39 %\n",
      "Epoch 14 of 500 took 1.293s\n",
      "  training loss:\t\t0.224288\n",
      "  validation loss:\t\t0.126149\n",
      "  validation accuracy:\t\t96.55 %\n",
      "Epoch 15 of 500 took 1.311s\n",
      "  training loss:\t\t0.217253\n",
      "  validation loss:\t\t0.120582\n",
      "  validation accuracy:\t\t96.63 %\n",
      "Epoch 16 of 500 took 1.310s\n",
      "  training loss:\t\t0.209145\n",
      "  validation loss:\t\t0.117726\n",
      "  validation accuracy:\t\t96.70 %\n",
      "Epoch 17 of 500 took 1.308s\n",
      "  training loss:\t\t0.201010\n",
      "  validation loss:\t\t0.113311\n",
      "  validation accuracy:\t\t96.83 %\n",
      "Epoch 18 of 500 took 1.304s\n",
      "  training loss:\t\t0.197117\n",
      "  validation loss:\t\t0.109287\n",
      "  validation accuracy:\t\t96.94 %\n",
      "Epoch 19 of 500 took 1.298s\n",
      "  training loss:\t\t0.191364\n",
      "  validation loss:\t\t0.107153\n",
      "  validation accuracy:\t\t97.03 %\n",
      "Epoch 20 of 500 took 1.324s\n",
      "  training loss:\t\t0.186855\n",
      "  validation loss:\t\t0.103455\n",
      "  validation accuracy:\t\t97.05 %\n",
      "Epoch 21 of 500 took 1.287s\n",
      "  training loss:\t\t0.178797\n",
      "  validation loss:\t\t0.101768\n",
      "  validation accuracy:\t\t97.14 %\n",
      "Epoch 22 of 500 took 1.291s\n",
      "  training loss:\t\t0.174810\n",
      "  validation loss:\t\t0.098628\n",
      "  validation accuracy:\t\t97.24 %\n",
      "Epoch 23 of 500 took 1.291s\n",
      "  training loss:\t\t0.168783\n",
      "  validation loss:\t\t0.097093\n",
      "  validation accuracy:\t\t97.34 %\n",
      "Epoch 24 of 500 took 1.312s\n",
      "  training loss:\t\t0.164496\n",
      "  validation loss:\t\t0.095262\n",
      "  validation accuracy:\t\t97.36 %\n",
      "Epoch 25 of 500 took 1.316s\n",
      "  training loss:\t\t0.160537\n",
      "  validation loss:\t\t0.093020\n",
      "  validation accuracy:\t\t97.44 %\n",
      "Epoch 26 of 500 took 1.315s\n",
      "  training loss:\t\t0.156887\n",
      "  validation loss:\t\t0.091148\n",
      "  validation accuracy:\t\t97.46 %\n",
      "Epoch 27 of 500 took 1.309s\n",
      "  training loss:\t\t0.156050\n",
      "  validation loss:\t\t0.088874\n",
      "  validation accuracy:\t\t97.46 %\n",
      "Epoch 28 of 500 took 1.289s\n",
      "  training loss:\t\t0.155469\n",
      "  validation loss:\t\t0.088294\n",
      "  validation accuracy:\t\t97.58 %\n",
      "Epoch 29 of 500 took 1.309s\n",
      "  training loss:\t\t0.151877\n",
      "  validation loss:\t\t0.086874\n",
      "  validation accuracy:\t\t97.56 %\n",
      "Epoch 30 of 500 took 1.309s\n",
      "  training loss:\t\t0.146138\n",
      "  validation loss:\t\t0.085204\n",
      "  validation accuracy:\t\t97.66 %\n",
      "Epoch 31 of 500 took 1.284s\n",
      "  training loss:\t\t0.141293\n",
      "  validation loss:\t\t0.083401\n",
      "  validation accuracy:\t\t97.61 %\n",
      "Epoch 32 of 500 took 1.308s\n",
      "  training loss:\t\t0.143307\n",
      "  validation loss:\t\t0.084265\n",
      "  validation accuracy:\t\t97.66 %\n",
      "Epoch 33 of 500 took 1.290s\n",
      "  training loss:\t\t0.138500\n",
      "  validation loss:\t\t0.081768\n",
      "  validation accuracy:\t\t97.71 %\n",
      "Epoch 34 of 500 took 1.303s\n",
      "  training loss:\t\t0.135702\n",
      "  validation loss:\t\t0.080620\n",
      "  validation accuracy:\t\t97.69 %\n",
      "Epoch 35 of 500 took 1.290s\n",
      "  training loss:\t\t0.136530\n",
      "  validation loss:\t\t0.079623\n",
      "  validation accuracy:\t\t97.72 %\n",
      "Epoch 36 of 500 took 1.305s\n",
      "  training loss:\t\t0.130264\n",
      "  validation loss:\t\t0.078605\n",
      "  validation accuracy:\t\t97.76 %\n",
      "Epoch 37 of 500 took 1.316s\n",
      "  training loss:\t\t0.129862\n",
      "  validation loss:\t\t0.077536\n",
      "  validation accuracy:\t\t97.72 %\n",
      "Epoch 38 of 500 took 1.298s\n",
      "  training loss:\t\t0.127089\n",
      "  validation loss:\t\t0.077028\n",
      "  validation accuracy:\t\t97.73 %\n",
      "Epoch 39 of 500 took 1.281s\n",
      "  training loss:\t\t0.125395\n",
      "  validation loss:\t\t0.076291\n",
      "  validation accuracy:\t\t97.78 %\n",
      "Epoch 40 of 500 took 1.304s\n",
      "  training loss:\t\t0.120574\n",
      "  validation loss:\t\t0.076029\n",
      "  validation accuracy:\t\t97.79 %\n",
      "Epoch 41 of 500 took 1.294s\n",
      "  training loss:\t\t0.120717\n",
      "  validation loss:\t\t0.076331\n",
      "  validation accuracy:\t\t97.80 %\n",
      "Epoch 42 of 500 took 1.293s\n",
      "  training loss:\t\t0.119252\n",
      "  validation loss:\t\t0.074647\n",
      "  validation accuracy:\t\t97.80 %\n",
      "Epoch 43 of 500 took 1.312s\n",
      "  training loss:\t\t0.116076\n",
      "  validation loss:\t\t0.073952\n",
      "  validation accuracy:\t\t97.87 %\n",
      "Epoch 44 of 500 took 1.305s\n",
      "  training loss:\t\t0.114642\n",
      "  validation loss:\t\t0.072396\n",
      "  validation accuracy:\t\t97.85 %\n",
      "Epoch 45 of 500 took 1.292s\n",
      "  training loss:\t\t0.114296\n",
      "  validation loss:\t\t0.073084\n",
      "  validation accuracy:\t\t97.81 %\n",
      "Epoch 46 of 500 took 1.321s\n",
      "  training loss:\t\t0.113677\n",
      "  validation loss:\t\t0.071771\n",
      "  validation accuracy:\t\t97.89 %\n",
      "Epoch 47 of 500 took 1.315s\n",
      "  training loss:\t\t0.109715\n",
      "  validation loss:\t\t0.071225\n",
      "  validation accuracy:\t\t97.86 %\n",
      "Epoch 48 of 500 took 1.306s\n",
      "  training loss:\t\t0.107011\n",
      "  validation loss:\t\t0.071155\n",
      "  validation accuracy:\t\t97.91 %\n",
      "Epoch 49 of 500 took 1.311s\n",
      "  training loss:\t\t0.106082\n",
      "  validation loss:\t\t0.070262\n",
      "  validation accuracy:\t\t97.92 %\n",
      "Epoch 50 of 500 took 1.306s\n",
      "  training loss:\t\t0.105905\n",
      "  validation loss:\t\t0.070323\n",
      "  validation accuracy:\t\t97.91 %\n",
      "Epoch 51 of 500 took 1.305s\n",
      "  training loss:\t\t0.104098\n",
      "  validation loss:\t\t0.069125\n",
      "  validation accuracy:\t\t97.91 %\n",
      "Epoch 52 of 500 took 1.295s\n",
      "  training loss:\t\t0.101020\n",
      "  validation loss:\t\t0.068686\n",
      "  validation accuracy:\t\t97.91 %\n",
      "Epoch 53 of 500 took 1.296s\n",
      "  training loss:\t\t0.102024\n",
      "  validation loss:\t\t0.068828\n",
      "  validation accuracy:\t\t97.97 %\n",
      "Epoch 54 of 500 took 1.311s\n",
      "  training loss:\t\t0.100750\n",
      "  validation loss:\t\t0.067601\n",
      "  validation accuracy:\t\t97.99 %\n",
      "Epoch 55 of 500 took 1.298s\n",
      "  training loss:\t\t0.100021\n",
      "  validation loss:\t\t0.066669\n",
      "  validation accuracy:\t\t98.02 %\n",
      "Epoch 56 of 500 took 1.304s\n",
      "  training loss:\t\t0.098052\n",
      "  validation loss:\t\t0.066894\n",
      "  validation accuracy:\t\t98.02 %\n",
      "Epoch 57 of 500 took 1.308s\n",
      "  training loss:\t\t0.097347\n",
      "  validation loss:\t\t0.066328\n",
      "  validation accuracy:\t\t98.05 %\n",
      "Epoch 58 of 500 took 1.302s\n",
      "  training loss:\t\t0.097851\n",
      "  validation loss:\t\t0.066466\n",
      "  validation accuracy:\t\t98.09 %\n",
      "Epoch 59 of 500 took 1.316s\n",
      "  training loss:\t\t0.094710\n",
      "  validation loss:\t\t0.065913\n",
      "  validation accuracy:\t\t98.08 %\n",
      "Epoch 60 of 500 took 1.423s\n",
      "  training loss:\t\t0.096081\n",
      "  validation loss:\t\t0.065504\n",
      "  validation accuracy:\t\t98.07 %\n",
      "Epoch 61 of 500 took 1.323s\n",
      "  training loss:\t\t0.093619\n",
      "  validation loss:\t\t0.064479\n",
      "  validation accuracy:\t\t98.11 %\n",
      "Epoch 62 of 500 took 1.309s\n",
      "  training loss:\t\t0.092168\n",
      "  validation loss:\t\t0.064112\n",
      "  validation accuracy:\t\t98.10 %\n",
      "Epoch 63 of 500 took 1.317s\n",
      "  training loss:\t\t0.092148\n",
      "  validation loss:\t\t0.065208\n",
      "  validation accuracy:\t\t98.08 %\n",
      "Epoch 64 of 500 took 1.311s\n",
      "  training loss:\t\t0.090804\n",
      "  validation loss:\t\t0.064638\n",
      "  validation accuracy:\t\t98.20 %\n",
      "Epoch 65 of 500 took 1.324s\n",
      "  training loss:\t\t0.089108\n",
      "  validation loss:\t\t0.064208\n",
      "  validation accuracy:\t\t98.09 %\n",
      "Epoch 66 of 500 took 1.293s\n",
      "  training loss:\t\t0.088277\n",
      "  validation loss:\t\t0.063668\n",
      "  validation accuracy:\t\t98.13 %\n",
      "Epoch 67 of 500 took 1.300s\n",
      "  training loss:\t\t0.087689\n",
      "  validation loss:\t\t0.063582\n",
      "  validation accuracy:\t\t98.18 %\n",
      "Epoch 68 of 500 took 1.293s\n",
      "  training loss:\t\t0.088946\n",
      "  validation loss:\t\t0.063424\n",
      "  validation accuracy:\t\t98.09 %\n",
      "Epoch 69 of 500 took 1.297s\n",
      "  training loss:\t\t0.086310\n",
      "  validation loss:\t\t0.063443\n",
      "  validation accuracy:\t\t98.17 %\n",
      "Epoch 70 of 500 took 1.300s\n",
      "  training loss:\t\t0.086074\n",
      "  validation loss:\t\t0.061653\n",
      "  validation accuracy:\t\t98.17 %\n",
      "Epoch 71 of 500 took 1.324s\n",
      "  training loss:\t\t0.085991\n",
      "  validation loss:\t\t0.062111\n",
      "  validation accuracy:\t\t98.13 %\n",
      "Epoch 72 of 500 took 1.285s\n",
      "  training loss:\t\t0.084707\n",
      "  validation loss:\t\t0.061672\n",
      "  validation accuracy:\t\t98.20 %\n",
      "Epoch 73 of 500 took 1.305s\n",
      "  training loss:\t\t0.080781\n",
      "  validation loss:\t\t0.061861\n",
      "  validation accuracy:\t\t98.17 %\n",
      "Epoch 74 of 500 took 1.293s\n",
      "  training loss:\t\t0.081555\n",
      "  validation loss:\t\t0.061050\n",
      "  validation accuracy:\t\t98.21 %\n",
      "Epoch 75 of 500 took 1.277s\n",
      "  training loss:\t\t0.081181\n",
      "  validation loss:\t\t0.061072\n",
      "  validation accuracy:\t\t98.23 %\n",
      "Epoch 76 of 500 took 1.298s\n",
      "  training loss:\t\t0.080154\n",
      "  validation loss:\t\t0.061311\n",
      "  validation accuracy:\t\t98.17 %\n",
      "Epoch 77 of 500 took 1.341s\n",
      "  training loss:\t\t0.078880\n",
      "  validation loss:\t\t0.061213\n",
      "  validation accuracy:\t\t98.15 %\n",
      "Epoch 78 of 500 took 1.307s\n",
      "  training loss:\t\t0.080350\n",
      "  validation loss:\t\t0.060804\n",
      "  validation accuracy:\t\t98.18 %\n",
      "Epoch 79 of 500 took 1.321s\n",
      "  training loss:\t\t0.077764\n",
      "  validation loss:\t\t0.061959\n",
      "  validation accuracy:\t\t98.16 %\n",
      "Epoch 80 of 500 took 1.297s\n",
      "  training loss:\t\t0.075861\n",
      "  validation loss:\t\t0.060733\n",
      "  validation accuracy:\t\t98.19 %\n",
      "Epoch 81 of 500 took 1.285s\n",
      "  training loss:\t\t0.078334\n",
      "  validation loss:\t\t0.060097\n",
      "  validation accuracy:\t\t98.23 %\n",
      "Epoch 82 of 500 took 1.290s\n",
      "  training loss:\t\t0.077621\n",
      "  validation loss:\t\t0.059438\n",
      "  validation accuracy:\t\t98.22 %\n",
      "Epoch 83 of 500 took 1.324s\n",
      "  training loss:\t\t0.077958\n",
      "  validation loss:\t\t0.059422\n",
      "  validation accuracy:\t\t98.23 %\n",
      "Epoch 84 of 500 took 1.334s\n",
      "  training loss:\t\t0.073742\n",
      "  validation loss:\t\t0.059314\n",
      "  validation accuracy:\t\t98.22 %\n",
      "Epoch 85 of 500 took 1.309s\n",
      "  training loss:\t\t0.073906\n",
      "  validation loss:\t\t0.058998\n",
      "  validation accuracy:\t\t98.30 %\n",
      "Epoch 86 of 500 took 1.326s\n",
      "  training loss:\t\t0.072094\n",
      "  validation loss:\t\t0.058440\n",
      "  validation accuracy:\t\t98.29 %\n",
      "Epoch 87 of 500 took 1.304s\n",
      "  training loss:\t\t0.070769\n",
      "  validation loss:\t\t0.059159\n",
      "  validation accuracy:\t\t98.31 %\n",
      "Epoch 88 of 500 took 1.327s\n",
      "  training loss:\t\t0.073856\n",
      "  validation loss:\t\t0.059692\n",
      "  validation accuracy:\t\t98.27 %\n",
      "Epoch 89 of 500 took 1.336s\n",
      "  training loss:\t\t0.070029\n",
      "  validation loss:\t\t0.058987\n",
      "  validation accuracy:\t\t98.35 %\n",
      "Epoch 90 of 500 took 1.325s\n",
      "  training loss:\t\t0.067449\n",
      "  validation loss:\t\t0.058910\n",
      "  validation accuracy:\t\t98.26 %\n",
      "Epoch 91 of 500 took 1.299s\n",
      "  training loss:\t\t0.070400\n",
      "  validation loss:\t\t0.058086\n",
      "  validation accuracy:\t\t98.30 %\n",
      "Epoch 92 of 500 took 1.306s\n",
      "  training loss:\t\t0.070345\n",
      "  validation loss:\t\t0.058701\n",
      "  validation accuracy:\t\t98.29 %\n",
      "Epoch 93 of 500 took 1.299s\n",
      "  training loss:\t\t0.067404\n",
      "  validation loss:\t\t0.057372\n",
      "  validation accuracy:\t\t98.32 %\n",
      "Epoch 94 of 500 took 1.304s\n",
      "  training loss:\t\t0.068544\n",
      "  validation loss:\t\t0.058636\n",
      "  validation accuracy:\t\t98.26 %\n",
      "Epoch 95 of 500 took 1.315s\n",
      "  training loss:\t\t0.067683\n",
      "  validation loss:\t\t0.057722\n",
      "  validation accuracy:\t\t98.31 %\n",
      "Epoch 96 of 500 took 1.339s\n",
      "  training loss:\t\t0.068522\n",
      "  validation loss:\t\t0.057273\n",
      "  validation accuracy:\t\t98.32 %\n",
      "Epoch 97 of 500 took 1.307s\n",
      "  training loss:\t\t0.068208\n",
      "  validation loss:\t\t0.057811\n",
      "  validation accuracy:\t\t98.24 %\n",
      "Epoch 98 of 500 took 1.321s\n",
      "  training loss:\t\t0.066321\n",
      "  validation loss:\t\t0.057954\n",
      "  validation accuracy:\t\t98.33 %\n",
      "Epoch 99 of 500 took 1.305s\n",
      "  training loss:\t\t0.064992\n",
      "  validation loss:\t\t0.057688\n",
      "  validation accuracy:\t\t98.38 %\n",
      "Epoch 100 of 500 took 1.335s\n",
      "  training loss:\t\t0.066454\n",
      "  validation loss:\t\t0.057211\n",
      "  validation accuracy:\t\t98.43 %\n",
      "Epoch 101 of 500 took 1.284s\n",
      "  training loss:\t\t0.065943\n",
      "  validation loss:\t\t0.057444\n",
      "  validation accuracy:\t\t98.37 %\n",
      "Epoch 102 of 500 took 1.338s\n",
      "  training loss:\t\t0.066120\n",
      "  validation loss:\t\t0.056800\n",
      "  validation accuracy:\t\t98.37 %\n",
      "Epoch 103 of 500 took 1.298s\n",
      "  training loss:\t\t0.064053\n",
      "  validation loss:\t\t0.056656\n",
      "  validation accuracy:\t\t98.38 %\n",
      "Epoch 104 of 500 took 1.323s\n",
      "  training loss:\t\t0.063455\n",
      "  validation loss:\t\t0.056458\n",
      "  validation accuracy:\t\t98.36 %\n",
      "Epoch 105 of 500 took 1.322s\n",
      "  training loss:\t\t0.064009\n",
      "  validation loss:\t\t0.055897\n",
      "  validation accuracy:\t\t98.37 %\n",
      "Epoch 106 of 500 took 1.334s\n",
      "  training loss:\t\t0.060787\n",
      "  validation loss:\t\t0.056598\n",
      "  validation accuracy:\t\t98.36 %\n",
      "Epoch 107 of 500 took 1.322s\n",
      "  training loss:\t\t0.063450\n",
      "  validation loss:\t\t0.055810\n",
      "  validation accuracy:\t\t98.39 %\n",
      "Epoch 108 of 500 took 1.304s\n",
      "  training loss:\t\t0.063821\n",
      "  validation loss:\t\t0.055470\n",
      "  validation accuracy:\t\t98.41 %\n",
      "Epoch 109 of 500 took 1.289s\n",
      "  training loss:\t\t0.061364\n",
      "  validation loss:\t\t0.055158\n",
      "  validation accuracy:\t\t98.43 %\n",
      "Epoch 110 of 500 took 1.314s\n",
      "  training loss:\t\t0.062407\n",
      "  validation loss:\t\t0.055564\n",
      "  validation accuracy:\t\t98.42 %\n",
      "Epoch 111 of 500 took 1.304s\n",
      "  training loss:\t\t0.061730\n",
      "  validation loss:\t\t0.055144\n",
      "  validation accuracy:\t\t98.41 %\n",
      "Epoch 112 of 500 took 1.305s\n",
      "  training loss:\t\t0.060403\n",
      "  validation loss:\t\t0.055860\n",
      "  validation accuracy:\t\t98.41 %\n",
      "Epoch 113 of 500 took 1.311s\n",
      "  training loss:\t\t0.059247\n",
      "  validation loss:\t\t0.055274\n",
      "  validation accuracy:\t\t98.42 %\n",
      "Epoch 114 of 500 took 1.312s\n",
      "  training loss:\t\t0.058836\n",
      "  validation loss:\t\t0.056083\n",
      "  validation accuracy:\t\t98.39 %\n",
      "Epoch 115 of 500 took 1.312s\n",
      "  training loss:\t\t0.058781\n",
      "  validation loss:\t\t0.055066\n",
      "  validation accuracy:\t\t98.43 %\n",
      "Epoch 116 of 500 took 1.307s\n",
      "  training loss:\t\t0.057230\n",
      "  validation loss:\t\t0.055891\n",
      "  validation accuracy:\t\t98.38 %\n",
      "Epoch 117 of 500 took 1.313s\n",
      "  training loss:\t\t0.058981\n",
      "  validation loss:\t\t0.055490\n",
      "  validation accuracy:\t\t98.42 %\n",
      "Epoch 118 of 500 took 1.308s\n",
      "  training loss:\t\t0.059186\n",
      "  validation loss:\t\t0.055650\n",
      "  validation accuracy:\t\t98.42 %\n",
      "Epoch 119 of 500 took 1.304s\n",
      "  training loss:\t\t0.055734\n",
      "  validation loss:\t\t0.055339\n",
      "  validation accuracy:\t\t98.38 %\n",
      "Epoch 120 of 500 took 1.319s\n",
      "  training loss:\t\t0.056566\n",
      "  validation loss:\t\t0.055650\n",
      "  validation accuracy:\t\t98.43 %\n",
      "Epoch 121 of 500 took 1.290s\n",
      "  training loss:\t\t0.057095\n",
      "  validation loss:\t\t0.055151\n",
      "  validation accuracy:\t\t98.46 %\n",
      "Epoch 122 of 500 took 1.330s\n",
      "  training loss:\t\t0.056833\n",
      "  validation loss:\t\t0.054640\n",
      "  validation accuracy:\t\t98.40 %\n",
      "Epoch 123 of 500 took 1.311s\n",
      "  training loss:\t\t0.055869\n",
      "  validation loss:\t\t0.055698\n",
      "  validation accuracy:\t\t98.41 %\n",
      "Epoch 124 of 500 took 1.307s\n",
      "  training loss:\t\t0.054995\n",
      "  validation loss:\t\t0.054519\n",
      "  validation accuracy:\t\t98.40 %\n",
      "Epoch 125 of 500 took 1.294s\n",
      "  training loss:\t\t0.057759\n",
      "  validation loss:\t\t0.054312\n",
      "  validation accuracy:\t\t98.45 %\n",
      "Epoch 126 of 500 took 1.287s\n",
      "  training loss:\t\t0.053664\n",
      "  validation loss:\t\t0.054669\n",
      "  validation accuracy:\t\t98.47 %\n",
      "Epoch 127 of 500 took 1.317s\n",
      "  training loss:\t\t0.055648\n",
      "  validation loss:\t\t0.053943\n",
      "  validation accuracy:\t\t98.43 %\n",
      "Epoch 128 of 500 took 1.337s\n",
      "  training loss:\t\t0.055007\n",
      "  validation loss:\t\t0.054247\n",
      "  validation accuracy:\t\t98.46 %\n",
      "Epoch 129 of 500 took 1.357s\n",
      "  training loss:\t\t0.054968\n",
      "  validation loss:\t\t0.053035\n",
      "  validation accuracy:\t\t98.49 %\n",
      "Epoch 130 of 500 took 1.352s\n",
      "  training loss:\t\t0.054153\n",
      "  validation loss:\t\t0.054818\n",
      "  validation accuracy:\t\t98.46 %\n",
      "Epoch 131 of 500 took 1.314s\n",
      "  training loss:\t\t0.055019\n",
      "  validation loss:\t\t0.053861\n",
      "  validation accuracy:\t\t98.48 %\n",
      "Epoch 132 of 500 took 1.321s\n",
      "  training loss:\t\t0.053090\n",
      "  validation loss:\t\t0.053563\n",
      "  validation accuracy:\t\t98.51 %\n",
      "Epoch 133 of 500 took 1.289s\n",
      "  training loss:\t\t0.053194\n",
      "  validation loss:\t\t0.053328\n",
      "  validation accuracy:\t\t98.54 %\n",
      "Epoch 134 of 500 took 1.337s\n",
      "  training loss:\t\t0.051164\n",
      "  validation loss:\t\t0.052822\n",
      "  validation accuracy:\t\t98.55 %\n",
      "Epoch 135 of 500 took 1.326s\n",
      "  training loss:\t\t0.054507\n",
      "  validation loss:\t\t0.053837\n",
      "  validation accuracy:\t\t98.56 %\n",
      "Epoch 136 of 500 took 1.324s\n",
      "  training loss:\t\t0.051692\n",
      "  validation loss:\t\t0.053741\n",
      "  validation accuracy:\t\t98.53 %\n",
      "Epoch 137 of 500 took 1.337s\n",
      "  training loss:\t\t0.051293\n",
      "  validation loss:\t\t0.054634\n",
      "  validation accuracy:\t\t98.51 %\n",
      "Epoch 138 of 500 took 1.332s\n",
      "  training loss:\t\t0.052819\n",
      "  validation loss:\t\t0.053587\n",
      "  validation accuracy:\t\t98.52 %\n",
      "Epoch 139 of 500 took 1.291s\n",
      "  training loss:\t\t0.049903\n",
      "  validation loss:\t\t0.052834\n",
      "  validation accuracy:\t\t98.45 %\n",
      "Epoch 140 of 500 took 1.325s\n",
      "  training loss:\t\t0.051996\n",
      "  validation loss:\t\t0.053036\n",
      "  validation accuracy:\t\t98.52 %\n",
      "Epoch 141 of 500 took 1.314s\n",
      "  training loss:\t\t0.052527\n",
      "  validation loss:\t\t0.052489\n",
      "  validation accuracy:\t\t98.50 %\n",
      "Epoch 142 of 500 took 1.325s\n",
      "  training loss:\t\t0.049735\n",
      "  validation loss:\t\t0.052668\n",
      "  validation accuracy:\t\t98.47 %\n",
      "Epoch 143 of 500 took 1.315s\n",
      "  training loss:\t\t0.049581\n",
      "  validation loss:\t\t0.053205\n",
      "  validation accuracy:\t\t98.50 %\n",
      "Epoch 144 of 500 took 1.298s\n",
      "  training loss:\t\t0.049423\n",
      "  validation loss:\t\t0.054217\n",
      "  validation accuracy:\t\t98.50 %\n",
      "Epoch 145 of 500 took 1.299s\n",
      "  training loss:\t\t0.049105\n",
      "  validation loss:\t\t0.053562\n",
      "  validation accuracy:\t\t98.49 %\n",
      "Epoch 146 of 500 took 1.288s\n",
      "  training loss:\t\t0.049328\n",
      "  validation loss:\t\t0.054149\n",
      "  validation accuracy:\t\t98.45 %\n",
      "Epoch 147 of 500 took 1.306s\n",
      "  training loss:\t\t0.048800\n",
      "  validation loss:\t\t0.054235\n",
      "  validation accuracy:\t\t98.44 %\n",
      "Epoch 148 of 500 took 1.311s\n",
      "  training loss:\t\t0.049383\n",
      "  validation loss:\t\t0.054118\n",
      "  validation accuracy:\t\t98.47 %\n",
      "Epoch 149 of 500 took 1.319s\n",
      "  training loss:\t\t0.046858\n",
      "  validation loss:\t\t0.053990\n",
      "  validation accuracy:\t\t98.52 %\n",
      "Epoch 150 of 500 took 1.328s\n",
      "  training loss:\t\t0.048356\n",
      "  validation loss:\t\t0.053317\n",
      "  validation accuracy:\t\t98.47 %\n",
      "Epoch 151 of 500 took 1.301s\n",
      "  training loss:\t\t0.048817\n",
      "  validation loss:\t\t0.053111\n",
      "  validation accuracy:\t\t98.52 %\n",
      "Epoch 152 of 500 took 1.344s\n",
      "  training loss:\t\t0.048918\n",
      "  validation loss:\t\t0.053169\n",
      "  validation accuracy:\t\t98.49 %\n",
      "Epoch 153 of 500 took 1.314s\n",
      "  training loss:\t\t0.048168\n",
      "  validation loss:\t\t0.053194\n",
      "  validation accuracy:\t\t98.51 %\n",
      "Epoch 154 of 500 took 1.283s\n",
      "  training loss:\t\t0.049085\n",
      "  validation loss:\t\t0.052282\n",
      "  validation accuracy:\t\t98.55 %\n",
      "Epoch 155 of 500 took 1.321s\n",
      "  training loss:\t\t0.045511\n",
      "  validation loss:\t\t0.052947\n",
      "  validation accuracy:\t\t98.49 %\n",
      "Epoch 156 of 500 took 1.288s\n",
      "  training loss:\t\t0.044911\n",
      "  validation loss:\t\t0.052861\n",
      "  validation accuracy:\t\t98.44 %\n",
      "Epoch 157 of 500 took 1.320s\n",
      "  training loss:\t\t0.046671\n",
      "  validation loss:\t\t0.053268\n",
      "  validation accuracy:\t\t98.48 %\n",
      "Epoch 158 of 500 took 1.326s\n",
      "  training loss:\t\t0.046946\n",
      "  validation loss:\t\t0.053565\n",
      "  validation accuracy:\t\t98.48 %\n",
      "Epoch 159 of 500 took 1.309s\n",
      "  training loss:\t\t0.047229\n",
      "  validation loss:\t\t0.052613\n",
      "  validation accuracy:\t\t98.54 %\n",
      "Epoch 160 of 500 took 1.331s\n",
      "  training loss:\t\t0.045728\n",
      "  validation loss:\t\t0.052437\n",
      "  validation accuracy:\t\t98.56 %\n",
      "Epoch 161 of 500 took 1.326s\n",
      "  training loss:\t\t0.044202\n",
      "  validation loss:\t\t0.052901\n",
      "  validation accuracy:\t\t98.55 %\n",
      "Epoch 162 of 500 took 1.336s\n",
      "  training loss:\t\t0.045489\n",
      "  validation loss:\t\t0.052793\n",
      "  validation accuracy:\t\t98.50 %\n",
      "Epoch 163 of 500 took 1.455s\n",
      "  training loss:\t\t0.045840\n",
      "  validation loss:\t\t0.052373\n",
      "  validation accuracy:\t\t98.56 %\n",
      "Epoch 164 of 500 took 1.319s\n",
      "  training loss:\t\t0.043412\n",
      "  validation loss:\t\t0.052325\n",
      "  validation accuracy:\t\t98.57 %\n",
      "Epoch 165 of 500 took 1.331s\n",
      "  training loss:\t\t0.044576\n",
      "  validation loss:\t\t0.052173\n",
      "  validation accuracy:\t\t98.59 %\n",
      "Epoch 166 of 500 took 1.308s\n",
      "  training loss:\t\t0.045662\n",
      "  validation loss:\t\t0.052504\n",
      "  validation accuracy:\t\t98.58 %\n",
      "Epoch 167 of 500 took 1.303s\n",
      "  training loss:\t\t0.045067\n",
      "  validation loss:\t\t0.052656\n",
      "  validation accuracy:\t\t98.51 %\n",
      "Epoch 168 of 500 took 1.300s\n",
      "  training loss:\t\t0.043866\n",
      "  validation loss:\t\t0.053234\n",
      "  validation accuracy:\t\t98.48 %\n",
      "Epoch 169 of 500 took 1.314s\n",
      "  training loss:\t\t0.045455\n",
      "  validation loss:\t\t0.052162\n",
      "  validation accuracy:\t\t98.57 %\n",
      "Epoch 170 of 500 took 1.289s\n",
      "  training loss:\t\t0.042459\n",
      "  validation loss:\t\t0.052466\n",
      "  validation accuracy:\t\t98.53 %\n",
      "Epoch 171 of 500 took 1.296s\n",
      "  training loss:\t\t0.044521\n",
      "  validation loss:\t\t0.051562\n",
      "  validation accuracy:\t\t98.55 %\n",
      "Epoch 172 of 500 took 1.324s\n",
      "  training loss:\t\t0.043456\n",
      "  validation loss:\t\t0.052597\n",
      "  validation accuracy:\t\t98.51 %\n",
      "Epoch 173 of 500 took 1.305s\n",
      "  training loss:\t\t0.041038\n",
      "  validation loss:\t\t0.052879\n",
      "  validation accuracy:\t\t98.47 %\n",
      "Epoch 174 of 500 took 1.319s\n",
      "  training loss:\t\t0.042627\n",
      "  validation loss:\t\t0.051861\n",
      "  validation accuracy:\t\t98.59 %\n",
      "Epoch 175 of 500 took 1.312s\n",
      "  training loss:\t\t0.041820\n",
      "  validation loss:\t\t0.052066\n",
      "  validation accuracy:\t\t98.57 %\n",
      "Epoch 176 of 500 took 1.306s\n",
      "  training loss:\t\t0.041101\n",
      "  validation loss:\t\t0.052966\n",
      "  validation accuracy:\t\t98.52 %\n",
      "Epoch 177 of 500 took 1.304s\n",
      "  training loss:\t\t0.042915\n",
      "  validation loss:\t\t0.052196\n",
      "  validation accuracy:\t\t98.51 %\n",
      "Epoch 178 of 500 took 1.302s\n",
      "  training loss:\t\t0.042877\n",
      "  validation loss:\t\t0.051403\n",
      "  validation accuracy:\t\t98.56 %\n",
      "Epoch 179 of 500 took 1.318s\n",
      "  training loss:\t\t0.041975\n",
      "  validation loss:\t\t0.052060\n",
      "  validation accuracy:\t\t98.53 %\n",
      "Epoch 180 of 500 took 1.305s\n",
      "  training loss:\t\t0.041488\n",
      "  validation loss:\t\t0.051979\n",
      "  validation accuracy:\t\t98.56 %\n",
      "Epoch 181 of 500 took 1.296s\n",
      "  training loss:\t\t0.041289\n",
      "  validation loss:\t\t0.051634\n",
      "  validation accuracy:\t\t98.55 %\n",
      "Epoch 182 of 500 took 1.328s\n",
      "  training loss:\t\t0.041601\n",
      "  validation loss:\t\t0.052235\n",
      "  validation accuracy:\t\t98.49 %\n",
      "Epoch 183 of 500 took 1.308s\n",
      "  training loss:\t\t0.042031\n",
      "  validation loss:\t\t0.050855\n",
      "  validation accuracy:\t\t98.59 %\n",
      "Epoch 184 of 500 took 1.306s\n",
      "  training loss:\t\t0.042671\n",
      "  validation loss:\t\t0.052497\n",
      "  validation accuracy:\t\t98.54 %\n",
      "Epoch 185 of 500 took 1.306s\n",
      "  training loss:\t\t0.039294\n",
      "  validation loss:\t\t0.050523\n",
      "  validation accuracy:\t\t98.54 %\n",
      "Epoch 186 of 500 took 1.302s\n",
      "  training loss:\t\t0.039689\n",
      "  validation loss:\t\t0.052565\n",
      "  validation accuracy:\t\t98.54 %\n",
      "Epoch 187 of 500 took 1.314s\n",
      "  training loss:\t\t0.039835\n",
      "  validation loss:\t\t0.052605\n",
      "  validation accuracy:\t\t98.51 %\n",
      "Epoch 188 of 500 took 1.310s\n",
      "  training loss:\t\t0.042718\n",
      "  validation loss:\t\t0.051150\n",
      "  validation accuracy:\t\t98.56 %\n",
      "Epoch 189 of 500 took 1.305s\n",
      "  training loss:\t\t0.039001\n",
      "  validation loss:\t\t0.052495\n",
      "  validation accuracy:\t\t98.64 %\n",
      "Epoch 190 of 500 took 1.303s\n",
      "  training loss:\t\t0.038410\n",
      "  validation loss:\t\t0.052360\n",
      "  validation accuracy:\t\t98.55 %\n",
      "Epoch 191 of 500 took 1.315s\n",
      "  training loss:\t\t0.039561\n",
      "  validation loss:\t\t0.051136\n",
      "  validation accuracy:\t\t98.58 %\n",
      "Epoch 192 of 500 took 1.288s\n",
      "  training loss:\t\t0.038641\n",
      "  validation loss:\t\t0.050922\n",
      "  validation accuracy:\t\t98.59 %\n",
      "Epoch 193 of 500 took 1.306s\n",
      "  training loss:\t\t0.038746\n",
      "  validation loss:\t\t0.052234\n",
      "  validation accuracy:\t\t98.50 %\n",
      "Epoch 194 of 500 took 1.304s\n",
      "  training loss:\t\t0.038050\n",
      "  validation loss:\t\t0.052567\n",
      "  validation accuracy:\t\t98.50 %\n",
      "Epoch 195 of 500 took 1.304s\n",
      "  training loss:\t\t0.039512\n",
      "  validation loss:\t\t0.051846\n",
      "  validation accuracy:\t\t98.56 %\n",
      "Epoch 196 of 500 took 1.302s\n",
      "  training loss:\t\t0.038701\n",
      "  validation loss:\t\t0.052110\n",
      "  validation accuracy:\t\t98.57 %\n",
      "Epoch 197 of 500 took 1.321s\n",
      "  training loss:\t\t0.037850\n",
      "  validation loss:\t\t0.051062\n",
      "  validation accuracy:\t\t98.60 %\n",
      "Epoch 198 of 500 took 1.305s\n",
      "  training loss:\t\t0.036790\n",
      "  validation loss:\t\t0.051087\n",
      "  validation accuracy:\t\t98.62 %\n",
      "Epoch 199 of 500 took 1.308s\n",
      "  training loss:\t\t0.037059\n",
      "  validation loss:\t\t0.051331\n",
      "  validation accuracy:\t\t98.59 %\n",
      "Epoch 200 of 500 took 1.303s\n",
      "  training loss:\t\t0.038020\n",
      "  validation loss:\t\t0.051221\n",
      "  validation accuracy:\t\t98.59 %\n",
      "Epoch 201 of 500 took 1.328s\n",
      "  training loss:\t\t0.037612\n",
      "  validation loss:\t\t0.052244\n",
      "  validation accuracy:\t\t98.58 %\n",
      "Epoch 202 of 500 took 1.317s\n",
      "  training loss:\t\t0.037809\n",
      "  validation loss:\t\t0.052101\n",
      "  validation accuracy:\t\t98.55 %\n",
      "Epoch 203 of 500 took 1.309s\n",
      "  training loss:\t\t0.037676\n",
      "  validation loss:\t\t0.051527\n",
      "  validation accuracy:\t\t98.61 %\n",
      "Epoch 204 of 500 took 1.307s\n",
      "  training loss:\t\t0.037243\n",
      "  validation loss:\t\t0.052199\n",
      "  validation accuracy:\t\t98.59 %\n",
      "Epoch 205 of 500 took 1.304s\n",
      "  training loss:\t\t0.036379\n",
      "  validation loss:\t\t0.051354\n",
      "  validation accuracy:\t\t98.57 %\n",
      "Epoch 206 of 500 took 1.295s\n",
      "  training loss:\t\t0.037519\n",
      "  validation loss:\t\t0.052256\n",
      "  validation accuracy:\t\t98.57 %\n",
      "Epoch 207 of 500 took 1.311s\n",
      "  training loss:\t\t0.037270\n",
      "  validation loss:\t\t0.052327\n",
      "  validation accuracy:\t\t98.60 %\n",
      "Epoch 208 of 500 took 1.306s\n",
      "  training loss:\t\t0.036959\n",
      "  validation loss:\t\t0.050770\n",
      "  validation accuracy:\t\t98.61 %\n",
      "Epoch 209 of 500 took 1.302s\n",
      "  training loss:\t\t0.034990\n",
      "  validation loss:\t\t0.052078\n",
      "  validation accuracy:\t\t98.53 %\n",
      "Epoch 210 of 500 took 1.279s\n",
      "  training loss:\t\t0.038045\n",
      "  validation loss:\t\t0.051765\n",
      "  validation accuracy:\t\t98.57 %\n",
      "Epoch 211 of 500 took 1.303s\n",
      "  training loss:\t\t0.037440\n",
      "  validation loss:\t\t0.050664\n",
      "  validation accuracy:\t\t98.53 %\n",
      "Epoch 212 of 500 took 1.310s\n",
      "  training loss:\t\t0.036311\n",
      "  validation loss:\t\t0.051421\n",
      "  validation accuracy:\t\t98.52 %\n",
      "Epoch 213 of 500 took 1.301s\n",
      "  training loss:\t\t0.035128\n",
      "  validation loss:\t\t0.051046\n",
      "  validation accuracy:\t\t98.59 %\n",
      "Epoch 214 of 500 took 1.283s\n",
      "  training loss:\t\t0.036830\n",
      "  validation loss:\t\t0.050695\n",
      "  validation accuracy:\t\t98.65 %\n",
      "Epoch 215 of 500 took 1.280s\n",
      "  training loss:\t\t0.035384\n",
      "  validation loss:\t\t0.051738\n",
      "  validation accuracy:\t\t98.56 %\n",
      "Epoch 216 of 500 took 1.303s\n",
      "  training loss:\t\t0.034875\n",
      "  validation loss:\t\t0.052508\n",
      "  validation accuracy:\t\t98.59 %\n",
      "Epoch 217 of 500 took 1.294s\n",
      "  training loss:\t\t0.034773\n",
      "  validation loss:\t\t0.051865\n",
      "  validation accuracy:\t\t98.63 %\n",
      "Epoch 218 of 500 took 1.302s\n",
      "  training loss:\t\t0.035760\n",
      "  validation loss:\t\t0.051627\n",
      "  validation accuracy:\t\t98.64 %\n",
      "Epoch 219 of 500 took 1.302s\n",
      "  training loss:\t\t0.034165\n",
      "  validation loss:\t\t0.051441\n",
      "  validation accuracy:\t\t98.64 %\n",
      "Epoch 220 of 500 took 1.282s\n",
      "  training loss:\t\t0.035077\n",
      "  validation loss:\t\t0.051719\n",
      "  validation accuracy:\t\t98.62 %\n",
      "Epoch 221 of 500 took 1.310s\n",
      "  training loss:\t\t0.034925\n",
      "  validation loss:\t\t0.051052\n",
      "  validation accuracy:\t\t98.59 %\n",
      "Epoch 222 of 500 took 1.312s\n",
      "  training loss:\t\t0.036388\n",
      "  validation loss:\t\t0.051549\n",
      "  validation accuracy:\t\t98.57 %\n",
      "Epoch 223 of 500 took 1.290s\n",
      "  training loss:\t\t0.033987\n",
      "  validation loss:\t\t0.053323\n",
      "  validation accuracy:\t\t98.57 %\n",
      "Epoch 224 of 500 took 1.299s\n",
      "  training loss:\t\t0.033918\n",
      "  validation loss:\t\t0.052103\n",
      "  validation accuracy:\t\t98.59 %\n",
      "Epoch 225 of 500 took 1.314s\n",
      "  training loss:\t\t0.032191\n",
      "  validation loss:\t\t0.052456\n",
      "  validation accuracy:\t\t98.56 %\n",
      "Epoch 226 of 500 took 1.293s\n",
      "  training loss:\t\t0.034709\n",
      "  validation loss:\t\t0.052178\n",
      "  validation accuracy:\t\t98.57 %\n",
      "Epoch 227 of 500 took 1.305s\n",
      "  training loss:\t\t0.033929\n",
      "  validation loss:\t\t0.051192\n",
      "  validation accuracy:\t\t98.64 %\n",
      "Epoch 228 of 500 took 1.312s\n",
      "  training loss:\t\t0.033632\n",
      "  validation loss:\t\t0.051267\n",
      "  validation accuracy:\t\t98.58 %\n",
      "Epoch 229 of 500 took 1.315s\n",
      "  training loss:\t\t0.033118\n",
      "  validation loss:\t\t0.052617\n",
      "  validation accuracy:\t\t98.55 %\n",
      "Epoch 230 of 500 took 1.299s\n",
      "  training loss:\t\t0.032959\n",
      "  validation loss:\t\t0.051397\n",
      "  validation accuracy:\t\t98.62 %\n",
      "Epoch 231 of 500 took 1.314s\n",
      "  training loss:\t\t0.033235\n",
      "  validation loss:\t\t0.051560\n",
      "  validation accuracy:\t\t98.59 %\n",
      "Epoch 232 of 500 took 1.332s\n",
      "  training loss:\t\t0.035148\n",
      "  validation loss:\t\t0.050765\n",
      "  validation accuracy:\t\t98.63 %\n",
      "Epoch 233 of 500 took 1.301s\n",
      "  training loss:\t\t0.032357\n",
      "  validation loss:\t\t0.051656\n",
      "  validation accuracy:\t\t98.63 %\n",
      "Epoch 234 of 500 took 1.298s\n",
      "  training loss:\t\t0.032675\n",
      "  validation loss:\t\t0.051021\n",
      "  validation accuracy:\t\t98.64 %\n",
      "Epoch 235 of 500 took 1.307s\n",
      "  training loss:\t\t0.034554\n",
      "  validation loss:\t\t0.051752\n",
      "  validation accuracy:\t\t98.65 %\n",
      "Epoch 236 of 500 took 1.287s\n",
      "  training loss:\t\t0.033107\n",
      "  validation loss:\t\t0.052501\n",
      "  validation accuracy:\t\t98.61 %\n",
      "Epoch 237 of 500 took 1.291s\n",
      "  training loss:\t\t0.033790\n",
      "  validation loss:\t\t0.050305\n",
      "  validation accuracy:\t\t98.68 %\n",
      "Epoch 238 of 500 took 1.334s\n",
      "  training loss:\t\t0.032629\n",
      "  validation loss:\t\t0.051123\n",
      "  validation accuracy:\t\t98.65 %\n",
      "Epoch 239 of 500 took 1.301s\n",
      "  training loss:\t\t0.034504\n",
      "  validation loss:\t\t0.051769\n",
      "  validation accuracy:\t\t98.59 %\n",
      "Epoch 240 of 500 took 1.309s\n",
      "  training loss:\t\t0.033197\n",
      "  validation loss:\t\t0.051900\n",
      "  validation accuracy:\t\t98.56 %\n",
      "Epoch 241 of 500 took 1.311s\n",
      "  training loss:\t\t0.032670\n",
      "  validation loss:\t\t0.051380\n",
      "  validation accuracy:\t\t98.59 %\n",
      "Epoch 242 of 500 took 1.290s\n",
      "  training loss:\t\t0.034386\n",
      "  validation loss:\t\t0.051317\n",
      "  validation accuracy:\t\t98.58 %\n",
      "Epoch 243 of 500 took 1.288s\n",
      "  training loss:\t\t0.033967\n",
      "  validation loss:\t\t0.051084\n",
      "  validation accuracy:\t\t98.63 %\n",
      "Epoch 244 of 500 took 1.301s\n",
      "  training loss:\t\t0.032658\n",
      "  validation loss:\t\t0.050867\n",
      "  validation accuracy:\t\t98.60 %\n",
      "Epoch 245 of 500 took 1.303s\n",
      "  training loss:\t\t0.031729\n",
      "  validation loss:\t\t0.051076\n",
      "  validation accuracy:\t\t98.63 %\n",
      "Epoch 246 of 500 took 1.309s\n",
      "  training loss:\t\t0.031990\n",
      "  validation loss:\t\t0.052291\n",
      "  validation accuracy:\t\t98.58 %\n",
      "Epoch 247 of 500 took 1.309s\n",
      "  training loss:\t\t0.032604\n",
      "  validation loss:\t\t0.051911\n",
      "  validation accuracy:\t\t98.61 %\n",
      "Epoch 248 of 500 took 1.305s\n",
      "  training loss:\t\t0.030163\n",
      "  validation loss:\t\t0.052753\n",
      "  validation accuracy:\t\t98.54 %\n",
      "Epoch 249 of 500 took 1.285s\n",
      "  training loss:\t\t0.031549\n",
      "  validation loss:\t\t0.051187\n",
      "  validation accuracy:\t\t98.61 %\n",
      "Epoch 250 of 500 took 1.295s\n",
      "  training loss:\t\t0.029186\n",
      "  validation loss:\t\t0.051486\n",
      "  validation accuracy:\t\t98.63 %\n",
      "Epoch 251 of 500 took 1.313s\n",
      "  training loss:\t\t0.033177\n",
      "  validation loss:\t\t0.051117\n",
      "  validation accuracy:\t\t98.67 %\n",
      "Epoch 252 of 500 took 1.291s\n",
      "  training loss:\t\t0.031313\n",
      "  validation loss:\t\t0.052040\n",
      "  validation accuracy:\t\t98.60 %\n",
      "Epoch 253 of 500 took 1.288s\n",
      "  training loss:\t\t0.030751\n",
      "  validation loss:\t\t0.051625\n",
      "  validation accuracy:\t\t98.66 %\n",
      "Epoch 254 of 500 took 1.310s\n",
      "  training loss:\t\t0.031621\n",
      "  validation loss:\t\t0.052483\n",
      "  validation accuracy:\t\t98.61 %\n",
      "Epoch 255 of 500 took 1.289s\n",
      "  training loss:\t\t0.030215\n",
      "  validation loss:\t\t0.050362\n",
      "  validation accuracy:\t\t98.68 %\n",
      "Epoch 256 of 500 took 1.292s\n",
      "  training loss:\t\t0.031709\n",
      "  validation loss:\t\t0.051567\n",
      "  validation accuracy:\t\t98.61 %\n",
      "Epoch 257 of 500 took 1.302s\n",
      "  training loss:\t\t0.028850\n",
      "  validation loss:\t\t0.052765\n",
      "  validation accuracy:\t\t98.59 %\n",
      "Epoch 258 of 500 took 1.291s\n",
      "  training loss:\t\t0.031141\n",
      "  validation loss:\t\t0.052343\n",
      "  validation accuracy:\t\t98.59 %\n",
      "Epoch 259 of 500 took 1.303s\n",
      "  training loss:\t\t0.029735\n",
      "  validation loss:\t\t0.051110\n",
      "  validation accuracy:\t\t98.65 %\n",
      "Epoch 260 of 500 took 1.284s\n",
      "  training loss:\t\t0.030765\n",
      "  validation loss:\t\t0.050839\n",
      "  validation accuracy:\t\t98.65 %\n",
      "Epoch 261 of 500 took 1.309s\n",
      "  training loss:\t\t0.029849\n",
      "  validation loss:\t\t0.051741\n",
      "  validation accuracy:\t\t98.66 %\n",
      "Epoch 262 of 500 took 1.302s\n",
      "  training loss:\t\t0.032129\n",
      "  validation loss:\t\t0.052803\n",
      "  validation accuracy:\t\t98.61 %\n",
      "Epoch 263 of 500 took 1.295s\n",
      "  training loss:\t\t0.030368\n",
      "  validation loss:\t\t0.051927\n",
      "  validation accuracy:\t\t98.69 %\n",
      "Epoch 264 of 500 took 1.294s\n",
      "  training loss:\t\t0.031150\n",
      "  validation loss:\t\t0.052172\n",
      "  validation accuracy:\t\t98.62 %\n",
      "Epoch 265 of 500 took 1.308s\n",
      "  training loss:\t\t0.030053\n",
      "  validation loss:\t\t0.051293\n",
      "  validation accuracy:\t\t98.66 %\n",
      "Epoch 266 of 500 took 1.292s\n",
      "  training loss:\t\t0.029360\n",
      "  validation loss:\t\t0.051740\n",
      "  validation accuracy:\t\t98.65 %\n",
      "Epoch 267 of 500 took 1.300s\n",
      "  training loss:\t\t0.030204\n",
      "  validation loss:\t\t0.052509\n",
      "  validation accuracy:\t\t98.62 %\n",
      "Epoch 268 of 500 took 1.292s\n",
      "  training loss:\t\t0.029803\n",
      "  validation loss:\t\t0.051587\n",
      "  validation accuracy:\t\t98.63 %\n",
      "Epoch 269 of 500 took 1.306s\n",
      "  training loss:\t\t0.029144\n",
      "  validation loss:\t\t0.051801\n",
      "  validation accuracy:\t\t98.63 %\n",
      "Epoch 270 of 500 took 1.320s\n",
      "  training loss:\t\t0.031341\n",
      "  validation loss:\t\t0.051615\n",
      "  validation accuracy:\t\t98.67 %\n",
      "Epoch 271 of 500 took 1.290s\n",
      "  training loss:\t\t0.028348\n",
      "  validation loss:\t\t0.051056\n",
      "  validation accuracy:\t\t98.66 %\n",
      "Epoch 272 of 500 took 1.298s\n",
      "  training loss:\t\t0.030083\n",
      "  validation loss:\t\t0.052483\n",
      "  validation accuracy:\t\t98.66 %\n",
      "Epoch 273 of 500 took 1.288s\n",
      "  training loss:\t\t0.028108\n",
      "  validation loss:\t\t0.052867\n",
      "  validation accuracy:\t\t98.66 %\n",
      "Epoch 274 of 500 took 1.313s\n",
      "  training loss:\t\t0.030129\n",
      "  validation loss:\t\t0.052073\n",
      "  validation accuracy:\t\t98.68 %\n",
      "Epoch 275 of 500 took 1.308s\n",
      "  training loss:\t\t0.028547\n",
      "  validation loss:\t\t0.051425\n",
      "  validation accuracy:\t\t98.68 %\n",
      "Epoch 276 of 500 took 1.296s\n",
      "  training loss:\t\t0.029310\n",
      "  validation loss:\t\t0.052519\n",
      "  validation accuracy:\t\t98.66 %\n",
      "Epoch 277 of 500 took 1.297s\n",
      "  training loss:\t\t0.028558\n",
      "  validation loss:\t\t0.051830\n",
      "  validation accuracy:\t\t98.67 %\n",
      "Epoch 278 of 500 took 1.301s\n",
      "  training loss:\t\t0.029152\n",
      "  validation loss:\t\t0.052390\n",
      "  validation accuracy:\t\t98.61 %\n",
      "Epoch 279 of 500 took 1.283s\n",
      "  training loss:\t\t0.029530\n",
      "  validation loss:\t\t0.052284\n",
      "  validation accuracy:\t\t98.58 %\n",
      "Epoch 280 of 500 took 1.302s\n",
      "  training loss:\t\t0.028201\n",
      "  validation loss:\t\t0.052114\n",
      "  validation accuracy:\t\t98.65 %\n",
      "Epoch 281 of 500 took 1.303s\n",
      "  training loss:\t\t0.027684\n",
      "  validation loss:\t\t0.053025\n",
      "  validation accuracy:\t\t98.65 %\n",
      "Epoch 282 of 500 took 1.298s\n",
      "  training loss:\t\t0.027116\n",
      "  validation loss:\t\t0.052096\n",
      "  validation accuracy:\t\t98.62 %\n",
      "Epoch 283 of 500 took 1.306s\n",
      "  training loss:\t\t0.028968\n",
      "  validation loss:\t\t0.052812\n",
      "  validation accuracy:\t\t98.69 %\n",
      "Epoch 284 of 500 took 1.314s\n",
      "  training loss:\t\t0.027117\n",
      "  validation loss:\t\t0.052279\n",
      "  validation accuracy:\t\t98.60 %\n",
      "Epoch 285 of 500 took 1.298s\n",
      "  training loss:\t\t0.027327\n",
      "  validation loss:\t\t0.052941\n",
      "  validation accuracy:\t\t98.59 %\n",
      "Epoch 286 of 500 took 1.297s\n",
      "  training loss:\t\t0.028144\n",
      "  validation loss:\t\t0.052423\n",
      "  validation accuracy:\t\t98.62 %\n",
      "Epoch 287 of 500 took 1.299s\n",
      "  training loss:\t\t0.027561\n",
      "  validation loss:\t\t0.051792\n",
      "  validation accuracy:\t\t98.62 %\n",
      "Epoch 288 of 500 took 1.302s\n",
      "  training loss:\t\t0.029557\n",
      "  validation loss:\t\t0.051638\n",
      "  validation accuracy:\t\t98.66 %\n",
      "Epoch 289 of 500 took 1.303s\n",
      "  training loss:\t\t0.029019\n",
      "  validation loss:\t\t0.051276\n",
      "  validation accuracy:\t\t98.67 %\n",
      "Epoch 290 of 500 took 1.288s\n",
      "  training loss:\t\t0.027961\n",
      "  validation loss:\t\t0.052228\n",
      "  validation accuracy:\t\t98.71 %\n",
      "Epoch 291 of 500 took 1.290s\n",
      "  training loss:\t\t0.027334\n",
      "  validation loss:\t\t0.052677\n",
      "  validation accuracy:\t\t98.66 %\n",
      "Epoch 292 of 500 took 1.295s\n",
      "  training loss:\t\t0.027721\n",
      "  validation loss:\t\t0.051207\n",
      "  validation accuracy:\t\t98.66 %\n",
      "Epoch 293 of 500 took 1.290s\n",
      "  training loss:\t\t0.025983\n",
      "  validation loss:\t\t0.052359\n",
      "  validation accuracy:\t\t98.64 %\n",
      "Epoch 294 of 500 took 1.306s\n",
      "  training loss:\t\t0.028021\n",
      "  validation loss:\t\t0.051242\n",
      "  validation accuracy:\t\t98.67 %\n",
      "Epoch 295 of 500 took 1.318s\n",
      "  training loss:\t\t0.026188\n",
      "  validation loss:\t\t0.052335\n",
      "  validation accuracy:\t\t98.67 %\n",
      "Epoch 296 of 500 took 1.305s\n",
      "  training loss:\t\t0.028229\n",
      "  validation loss:\t\t0.052998\n",
      "  validation accuracy:\t\t98.65 %\n",
      "Epoch 297 of 500 took 1.300s\n",
      "  training loss:\t\t0.029163\n",
      "  validation loss:\t\t0.051550\n",
      "  validation accuracy:\t\t98.66 %\n",
      "Epoch 298 of 500 took 1.301s\n",
      "  training loss:\t\t0.027472\n",
      "  validation loss:\t\t0.052779\n",
      "  validation accuracy:\t\t98.63 %\n",
      "Epoch 299 of 500 took 1.307s\n",
      "  training loss:\t\t0.028177\n",
      "  validation loss:\t\t0.051676\n",
      "  validation accuracy:\t\t98.65 %\n",
      "Epoch 300 of 500 took 1.303s\n",
      "  training loss:\t\t0.026366\n",
      "  validation loss:\t\t0.051700\n",
      "  validation accuracy:\t\t98.65 %\n",
      "Epoch 301 of 500 took 1.283s\n",
      "  training loss:\t\t0.026311\n",
      "  validation loss:\t\t0.053092\n",
      "  validation accuracy:\t\t98.67 %\n",
      "Epoch 302 of 500 took 1.325s\n",
      "  training loss:\t\t0.026692\n",
      "  validation loss:\t\t0.052805\n",
      "  validation accuracy:\t\t98.66 %\n",
      "Epoch 303 of 500 took 1.318s\n",
      "  training loss:\t\t0.025428\n",
      "  validation loss:\t\t0.053030\n",
      "  validation accuracy:\t\t98.63 %\n",
      "Epoch 304 of 500 took 1.320s\n",
      "  training loss:\t\t0.025635\n",
      "  validation loss:\t\t0.052158\n",
      "  validation accuracy:\t\t98.67 %\n",
      "Epoch 305 of 500 took 1.298s\n",
      "  training loss:\t\t0.026484\n",
      "  validation loss:\t\t0.052523\n",
      "  validation accuracy:\t\t98.72 %\n",
      "Epoch 306 of 500 took 1.297s\n",
      "  training loss:\t\t0.028359\n",
      "  validation loss:\t\t0.051376\n",
      "  validation accuracy:\t\t98.65 %\n",
      "Epoch 307 of 500 took 1.310s\n",
      "  training loss:\t\t0.026711\n",
      "  validation loss:\t\t0.050533\n",
      "  validation accuracy:\t\t98.70 %\n",
      "Epoch 308 of 500 took 1.295s\n",
      "  training loss:\t\t0.028268\n",
      "  validation loss:\t\t0.051247\n",
      "  validation accuracy:\t\t98.66 %\n",
      "Epoch 309 of 500 took 1.302s\n",
      "  training loss:\t\t0.026365\n",
      "  validation loss:\t\t0.051910\n",
      "  validation accuracy:\t\t98.67 %\n",
      "Epoch 310 of 500 took 1.293s\n",
      "  training loss:\t\t0.025121\n",
      "  validation loss:\t\t0.051683\n",
      "  validation accuracy:\t\t98.69 %\n",
      "Epoch 311 of 500 took 1.300s\n",
      "  training loss:\t\t0.026549\n",
      "  validation loss:\t\t0.052464\n",
      "  validation accuracy:\t\t98.68 %\n",
      "Epoch 312 of 500 took 1.297s\n",
      "  training loss:\t\t0.026593\n",
      "  validation loss:\t\t0.052500\n",
      "  validation accuracy:\t\t98.66 %\n",
      "Epoch 313 of 500 took 1.281s\n",
      "  training loss:\t\t0.027731\n",
      "  validation loss:\t\t0.051310\n",
      "  validation accuracy:\t\t98.65 %\n",
      "Epoch 314 of 500 took 1.276s\n",
      "  training loss:\t\t0.025596\n",
      "  validation loss:\t\t0.051494\n",
      "  validation accuracy:\t\t98.72 %\n",
      "Epoch 315 of 500 took 1.296s\n",
      "  training loss:\t\t0.026597\n",
      "  validation loss:\t\t0.052113\n",
      "  validation accuracy:\t\t98.70 %\n",
      "Epoch 316 of 500 took 1.289s\n",
      "  training loss:\t\t0.025349\n",
      "  validation loss:\t\t0.052181\n",
      "  validation accuracy:\t\t98.68 %\n",
      "Epoch 317 of 500 took 1.303s\n",
      "  training loss:\t\t0.026275\n",
      "  validation loss:\t\t0.052524\n",
      "  validation accuracy:\t\t98.67 %\n",
      "Epoch 318 of 500 took 1.282s\n",
      "  training loss:\t\t0.023782\n",
      "  validation loss:\t\t0.052544\n",
      "  validation accuracy:\t\t98.63 %\n",
      "Epoch 319 of 500 took 1.302s\n",
      "  training loss:\t\t0.024906\n",
      "  validation loss:\t\t0.051316\n",
      "  validation accuracy:\t\t98.69 %\n",
      "Epoch 320 of 500 took 1.314s\n",
      "  training loss:\t\t0.027193\n",
      "  validation loss:\t\t0.051493\n",
      "  validation accuracy:\t\t98.67 %\n",
      "Epoch 321 of 500 took 1.309s\n",
      "  training loss:\t\t0.026680\n",
      "  validation loss:\t\t0.051830\n",
      "  validation accuracy:\t\t98.68 %\n",
      "Epoch 322 of 500 took 1.300s\n",
      "  training loss:\t\t0.026000\n",
      "  validation loss:\t\t0.051121\n",
      "  validation accuracy:\t\t98.71 %\n",
      "Epoch 323 of 500 took 1.307s\n",
      "  training loss:\t\t0.024589\n",
      "  validation loss:\t\t0.049853\n",
      "  validation accuracy:\t\t98.68 %\n",
      "Epoch 324 of 500 took 1.300s\n",
      "  training loss:\t\t0.026442\n",
      "  validation loss:\t\t0.052192\n",
      "  validation accuracy:\t\t98.68 %\n",
      "Epoch 325 of 500 took 1.298s\n",
      "  training loss:\t\t0.024835\n",
      "  validation loss:\t\t0.051891\n",
      "  validation accuracy:\t\t98.62 %\n",
      "Epoch 326 of 500 took 1.302s\n",
      "  training loss:\t\t0.024612\n",
      "  validation loss:\t\t0.052552\n",
      "  validation accuracy:\t\t98.61 %\n",
      "Epoch 327 of 500 took 1.285s\n",
      "  training loss:\t\t0.025688\n",
      "  validation loss:\t\t0.052023\n",
      "  validation accuracy:\t\t98.63 %\n",
      "Epoch 328 of 500 took 1.291s\n",
      "  training loss:\t\t0.025942\n",
      "  validation loss:\t\t0.052347\n",
      "  validation accuracy:\t\t98.67 %\n",
      "Epoch 329 of 500 took 1.298s\n",
      "  training loss:\t\t0.025315\n",
      "  validation loss:\t\t0.051637\n",
      "  validation accuracy:\t\t98.62 %\n",
      "Epoch 330 of 500 took 1.285s\n",
      "  training loss:\t\t0.025007\n",
      "  validation loss:\t\t0.051770\n",
      "  validation accuracy:\t\t98.68 %\n",
      "Epoch 331 of 500 took 1.284s\n",
      "  training loss:\t\t0.025138\n",
      "  validation loss:\t\t0.051625\n",
      "  validation accuracy:\t\t98.65 %\n",
      "Epoch 332 of 500 took 1.283s\n",
      "  training loss:\t\t0.025437\n",
      "  validation loss:\t\t0.051097\n",
      "  validation accuracy:\t\t98.70 %\n",
      "Epoch 333 of 500 took 1.283s\n",
      "  training loss:\t\t0.024813\n",
      "  validation loss:\t\t0.052021\n",
      "  validation accuracy:\t\t98.67 %\n",
      "Epoch 334 of 500 took 1.301s\n",
      "  training loss:\t\t0.025995\n",
      "  validation loss:\t\t0.051327\n",
      "  validation accuracy:\t\t98.65 %\n",
      "Epoch 335 of 500 took 1.291s\n",
      "  training loss:\t\t0.022763\n",
      "  validation loss:\t\t0.052476\n",
      "  validation accuracy:\t\t98.68 %\n",
      "Epoch 336 of 500 took 1.300s\n",
      "  training loss:\t\t0.024586\n",
      "  validation loss:\t\t0.053122\n",
      "  validation accuracy:\t\t98.64 %\n",
      "Epoch 337 of 500 took 1.281s\n",
      "  training loss:\t\t0.024180\n",
      "  validation loss:\t\t0.052320\n",
      "  validation accuracy:\t\t98.62 %\n",
      "Epoch 338 of 500 took 1.292s\n",
      "  training loss:\t\t0.024889\n",
      "  validation loss:\t\t0.051096\n",
      "  validation accuracy:\t\t98.72 %\n",
      "Epoch 339 of 500 took 1.293s\n",
      "  training loss:\t\t0.024981\n",
      "  validation loss:\t\t0.052108\n",
      "  validation accuracy:\t\t98.61 %\n",
      "Epoch 340 of 500 took 1.303s\n",
      "  training loss:\t\t0.025264\n",
      "  validation loss:\t\t0.052679\n",
      "  validation accuracy:\t\t98.67 %\n",
      "Epoch 341 of 500 took 1.296s\n",
      "  training loss:\t\t0.023231\n",
      "  validation loss:\t\t0.053013\n",
      "  validation accuracy:\t\t98.64 %\n",
      "Epoch 342 of 500 took 1.303s\n",
      "  training loss:\t\t0.024269\n",
      "  validation loss:\t\t0.052435\n",
      "  validation accuracy:\t\t98.65 %\n",
      "Epoch 343 of 500 took 1.289s\n",
      "  training loss:\t\t0.023236\n",
      "  validation loss:\t\t0.052244\n",
      "  validation accuracy:\t\t98.68 %\n",
      "Epoch 344 of 500 took 1.289s\n",
      "  training loss:\t\t0.025043\n",
      "  validation loss:\t\t0.052082\n",
      "  validation accuracy:\t\t98.67 %\n",
      "Epoch 345 of 500 took 1.291s\n",
      "  training loss:\t\t0.023396\n",
      "  validation loss:\t\t0.051637\n",
      "  validation accuracy:\t\t98.64 %\n",
      "Epoch 346 of 500 took 1.285s\n",
      "  training loss:\t\t0.024850\n",
      "  validation loss:\t\t0.051291\n",
      "  validation accuracy:\t\t98.64 %\n",
      "Epoch 347 of 500 took 1.295s\n",
      "  training loss:\t\t0.023459\n",
      "  validation loss:\t\t0.051840\n",
      "  validation accuracy:\t\t98.74 %\n",
      "Epoch 348 of 500 took 1.282s\n",
      "  training loss:\t\t0.023602\n",
      "  validation loss:\t\t0.052680\n",
      "  validation accuracy:\t\t98.73 %\n",
      "Epoch 349 of 500 took 1.311s\n",
      "  training loss:\t\t0.023774\n",
      "  validation loss:\t\t0.052760\n",
      "  validation accuracy:\t\t98.63 %\n",
      "Epoch 350 of 500 took 1.281s\n",
      "  training loss:\t\t0.024540\n",
      "  validation loss:\t\t0.052627\n",
      "  validation accuracy:\t\t98.69 %\n",
      "Epoch 351 of 500 took 1.296s\n",
      "  training loss:\t\t0.024742\n",
      "  validation loss:\t\t0.050930\n",
      "  validation accuracy:\t\t98.67 %\n",
      "Epoch 352 of 500 took 1.285s\n",
      "  training loss:\t\t0.025400\n",
      "  validation loss:\t\t0.051772\n",
      "  validation accuracy:\t\t98.73 %\n",
      "Epoch 353 of 500 took 1.278s\n",
      "  training loss:\t\t0.024080\n",
      "  validation loss:\t\t0.052634\n",
      "  validation accuracy:\t\t98.68 %\n",
      "Epoch 354 of 500 took 1.294s\n",
      "  training loss:\t\t0.023217\n",
      "  validation loss:\t\t0.052401\n",
      "  validation accuracy:\t\t98.68 %\n",
      "Epoch 355 of 500 took 1.291s\n",
      "  training loss:\t\t0.023685\n",
      "  validation loss:\t\t0.052552\n",
      "  validation accuracy:\t\t98.71 %\n",
      "Epoch 356 of 500 took 1.292s\n",
      "  training loss:\t\t0.023673\n",
      "  validation loss:\t\t0.052499\n",
      "  validation accuracy:\t\t98.69 %\n",
      "Epoch 357 of 500 took 1.283s\n",
      "  training loss:\t\t0.024279\n",
      "  validation loss:\t\t0.051326\n",
      "  validation accuracy:\t\t98.67 %\n",
      "Epoch 358 of 500 took 1.297s\n",
      "  training loss:\t\t0.022511\n",
      "  validation loss:\t\t0.052452\n",
      "  validation accuracy:\t\t98.70 %\n",
      "Epoch 359 of 500 took 1.285s\n",
      "  training loss:\t\t0.024268\n",
      "  validation loss:\t\t0.052695\n",
      "  validation accuracy:\t\t98.67 %\n",
      "Epoch 360 of 500 took 1.302s\n",
      "  training loss:\t\t0.023940\n",
      "  validation loss:\t\t0.052242\n",
      "  validation accuracy:\t\t98.63 %\n",
      "Epoch 361 of 500 took 1.280s\n",
      "  training loss:\t\t0.022635\n",
      "  validation loss:\t\t0.052480\n",
      "  validation accuracy:\t\t98.66 %\n",
      "Epoch 362 of 500 took 1.295s\n",
      "  training loss:\t\t0.023874\n",
      "  validation loss:\t\t0.051310\n",
      "  validation accuracy:\t\t98.72 %\n",
      "Epoch 363 of 500 took 1.284s\n",
      "  training loss:\t\t0.023097\n",
      "  validation loss:\t\t0.051183\n",
      "  validation accuracy:\t\t98.75 %\n",
      "Epoch 364 of 500 took 1.297s\n",
      "  training loss:\t\t0.022527\n",
      "  validation loss:\t\t0.051331\n",
      "  validation accuracy:\t\t98.71 %\n",
      "Epoch 365 of 500 took 1.299s\n",
      "  training loss:\t\t0.022964\n",
      "  validation loss:\t\t0.051112\n",
      "  validation accuracy:\t\t98.81 %\n",
      "Epoch 366 of 500 took 1.296s\n",
      "  training loss:\t\t0.021740\n",
      "  validation loss:\t\t0.050724\n",
      "  validation accuracy:\t\t98.74 %\n",
      "Epoch 367 of 500 took 1.308s\n",
      "  training loss:\t\t0.023079\n",
      "  validation loss:\t\t0.052027\n",
      "  validation accuracy:\t\t98.74 %\n",
      "Epoch 368 of 500 took 1.294s\n",
      "  training loss:\t\t0.021949\n",
      "  validation loss:\t\t0.052971\n",
      "  validation accuracy:\t\t98.70 %\n",
      "Epoch 369 of 500 took 1.299s\n",
      "  training loss:\t\t0.023157\n",
      "  validation loss:\t\t0.051833\n",
      "  validation accuracy:\t\t98.69 %\n",
      "Epoch 370 of 500 took 1.292s\n",
      "  training loss:\t\t0.022921\n",
      "  validation loss:\t\t0.052663\n",
      "  validation accuracy:\t\t98.69 %\n",
      "Epoch 371 of 500 took 1.292s\n",
      "  training loss:\t\t0.022306\n",
      "  validation loss:\t\t0.051778\n",
      "  validation accuracy:\t\t98.70 %\n",
      "Epoch 372 of 500 took 1.300s\n",
      "  training loss:\t\t0.022232\n",
      "  validation loss:\t\t0.051811\n",
      "  validation accuracy:\t\t98.73 %\n",
      "Epoch 373 of 500 took 1.293s\n",
      "  training loss:\t\t0.021890\n",
      "  validation loss:\t\t0.052991\n",
      "  validation accuracy:\t\t98.71 %\n",
      "Epoch 374 of 500 took 1.295s\n",
      "  training loss:\t\t0.021782\n",
      "  validation loss:\t\t0.053087\n",
      "  validation accuracy:\t\t98.73 %\n",
      "Epoch 375 of 500 took 1.298s\n",
      "  training loss:\t\t0.023143\n",
      "  validation loss:\t\t0.052765\n",
      "  validation accuracy:\t\t98.70 %\n",
      "Epoch 376 of 500 took 1.294s\n",
      "  training loss:\t\t0.020780\n",
      "  validation loss:\t\t0.052331\n",
      "  validation accuracy:\t\t98.69 %\n",
      "Epoch 377 of 500 took 1.287s\n",
      "  training loss:\t\t0.022214\n",
      "  validation loss:\t\t0.053034\n",
      "  validation accuracy:\t\t98.74 %\n",
      "Epoch 378 of 500 took 1.311s\n",
      "  training loss:\t\t0.022084\n",
      "  validation loss:\t\t0.053657\n",
      "  validation accuracy:\t\t98.68 %\n",
      "Epoch 379 of 500 took 1.294s\n",
      "  training loss:\t\t0.024181\n",
      "  validation loss:\t\t0.051991\n",
      "  validation accuracy:\t\t98.67 %\n",
      "Epoch 380 of 500 took 1.307s\n",
      "  training loss:\t\t0.023186\n",
      "  validation loss:\t\t0.053971\n",
      "  validation accuracy:\t\t98.69 %\n",
      "Epoch 381 of 500 took 1.313s\n",
      "  training loss:\t\t0.022274\n",
      "  validation loss:\t\t0.052880\n",
      "  validation accuracy:\t\t98.67 %\n",
      "Epoch 382 of 500 took 1.299s\n",
      "  training loss:\t\t0.022471\n",
      "  validation loss:\t\t0.052030\n",
      "  validation accuracy:\t\t98.67 %\n",
      "Epoch 383 of 500 took 1.309s\n",
      "  training loss:\t\t0.023962\n",
      "  validation loss:\t\t0.051407\n",
      "  validation accuracy:\t\t98.64 %\n",
      "Epoch 384 of 500 took 1.286s\n",
      "  training loss:\t\t0.020874\n",
      "  validation loss:\t\t0.052480\n",
      "  validation accuracy:\t\t98.62 %\n",
      "Epoch 385 of 500 took 1.278s\n",
      "  training loss:\t\t0.021772\n",
      "  validation loss:\t\t0.052541\n",
      "  validation accuracy:\t\t98.68 %\n",
      "Epoch 386 of 500 took 1.316s\n",
      "  training loss:\t\t0.021242\n",
      "  validation loss:\t\t0.052060\n",
      "  validation accuracy:\t\t98.71 %\n",
      "Epoch 387 of 500 took 1.296s\n",
      "  training loss:\t\t0.022772\n",
      "  validation loss:\t\t0.051621\n",
      "  validation accuracy:\t\t98.69 %\n",
      "Epoch 388 of 500 took 1.292s\n",
      "  training loss:\t\t0.021992\n",
      "  validation loss:\t\t0.051535\n",
      "  validation accuracy:\t\t98.70 %\n",
      "Epoch 389 of 500 took 1.292s\n",
      "  training loss:\t\t0.021677\n",
      "  validation loss:\t\t0.052812\n",
      "  validation accuracy:\t\t98.68 %\n",
      "Epoch 390 of 500 took 1.292s\n",
      "  training loss:\t\t0.021983\n",
      "  validation loss:\t\t0.052515\n",
      "  validation accuracy:\t\t98.67 %\n",
      "Epoch 391 of 500 took 1.291s\n",
      "  training loss:\t\t0.020732\n",
      "  validation loss:\t\t0.052210\n",
      "  validation accuracy:\t\t98.71 %\n",
      "Epoch 392 of 500 took 1.293s\n",
      "  training loss:\t\t0.020880\n",
      "  validation loss:\t\t0.053435\n",
      "  validation accuracy:\t\t98.67 %\n",
      "Epoch 393 of 500 took 1.312s\n",
      "  training loss:\t\t0.021368\n",
      "  validation loss:\t\t0.052139\n",
      "  validation accuracy:\t\t98.74 %\n",
      "Epoch 394 of 500 took 1.285s\n",
      "  training loss:\t\t0.022196\n",
      "  validation loss:\t\t0.052816\n",
      "  validation accuracy:\t\t98.69 %\n",
      "Epoch 395 of 500 took 1.287s\n",
      "  training loss:\t\t0.022044\n",
      "  validation loss:\t\t0.052549\n",
      "  validation accuracy:\t\t98.69 %\n",
      "Epoch 396 of 500 took 1.293s\n",
      "  training loss:\t\t0.023254\n",
      "  validation loss:\t\t0.051785\n",
      "  validation accuracy:\t\t98.67 %\n",
      "Epoch 397 of 500 took 1.289s\n",
      "  training loss:\t\t0.022688\n",
      "  validation loss:\t\t0.052312\n",
      "  validation accuracy:\t\t98.68 %\n",
      "Epoch 398 of 500 took 1.298s\n",
      "  training loss:\t\t0.021134\n",
      "  validation loss:\t\t0.051763\n",
      "  validation accuracy:\t\t98.72 %\n",
      "Epoch 399 of 500 took 1.296s\n",
      "  training loss:\t\t0.020671\n",
      "  validation loss:\t\t0.052768\n",
      "  validation accuracy:\t\t98.70 %\n",
      "Epoch 400 of 500 took 1.305s\n",
      "  training loss:\t\t0.021540\n",
      "  validation loss:\t\t0.052657\n",
      "  validation accuracy:\t\t98.68 %\n",
      "Epoch 401 of 500 took 1.300s\n",
      "  training loss:\t\t0.020296\n",
      "  validation loss:\t\t0.052212\n",
      "  validation accuracy:\t\t98.71 %\n",
      "Epoch 402 of 500 took 1.286s\n",
      "  training loss:\t\t0.022122\n",
      "  validation loss:\t\t0.051593\n",
      "  validation accuracy:\t\t98.72 %\n",
      "Epoch 403 of 500 took 1.311s\n",
      "  training loss:\t\t0.021624\n",
      "  validation loss:\t\t0.050960\n",
      "  validation accuracy:\t\t98.71 %\n",
      "Epoch 404 of 500 took 1.294s\n",
      "  training loss:\t\t0.021471\n",
      "  validation loss:\t\t0.052204\n",
      "  validation accuracy:\t\t98.69 %\n",
      "Epoch 405 of 500 took 1.300s\n",
      "  training loss:\t\t0.020981\n",
      "  validation loss:\t\t0.052591\n",
      "  validation accuracy:\t\t98.65 %\n",
      "Epoch 406 of 500 took 1.296s\n",
      "  training loss:\t\t0.021489\n",
      "  validation loss:\t\t0.052041\n",
      "  validation accuracy:\t\t98.66 %\n",
      "Epoch 407 of 500 took 1.316s\n",
      "  training loss:\t\t0.021036\n",
      "  validation loss:\t\t0.051823\n",
      "  validation accuracy:\t\t98.69 %\n",
      "Epoch 408 of 500 took 1.298s\n",
      "  training loss:\t\t0.022075\n",
      "  validation loss:\t\t0.052156\n",
      "  validation accuracy:\t\t98.71 %\n",
      "Epoch 409 of 500 took 1.295s\n",
      "  training loss:\t\t0.020983\n",
      "  validation loss:\t\t0.052516\n",
      "  validation accuracy:\t\t98.68 %\n",
      "Epoch 410 of 500 took 1.302s\n",
      "  training loss:\t\t0.021786\n",
      "  validation loss:\t\t0.052766\n",
      "  validation accuracy:\t\t98.69 %\n",
      "Epoch 411 of 500 took 1.285s\n",
      "  training loss:\t\t0.021693\n",
      "  validation loss:\t\t0.052982\n",
      "  validation accuracy:\t\t98.69 %\n",
      "Epoch 412 of 500 took 1.303s\n",
      "  training loss:\t\t0.021699\n",
      "  validation loss:\t\t0.052296\n",
      "  validation accuracy:\t\t98.74 %\n",
      "Epoch 413 of 500 took 1.293s\n",
      "  training loss:\t\t0.020554\n",
      "  validation loss:\t\t0.052486\n",
      "  validation accuracy:\t\t98.65 %\n",
      "Epoch 414 of 500 took 1.307s\n",
      "  training loss:\t\t0.020051\n",
      "  validation loss:\t\t0.052489\n",
      "  validation accuracy:\t\t98.71 %\n",
      "Epoch 415 of 500 took 1.301s\n",
      "  training loss:\t\t0.021283\n",
      "  validation loss:\t\t0.054338\n",
      "  validation accuracy:\t\t98.66 %\n",
      "Epoch 416 of 500 took 1.302s\n",
      "  training loss:\t\t0.019982\n",
      "  validation loss:\t\t0.052595\n",
      "  validation accuracy:\t\t98.64 %\n",
      "Epoch 417 of 500 took 1.312s\n",
      "  training loss:\t\t0.020026\n",
      "  validation loss:\t\t0.052534\n",
      "  validation accuracy:\t\t98.72 %\n",
      "Epoch 418 of 500 took 1.327s\n",
      "  training loss:\t\t0.020903\n",
      "  validation loss:\t\t0.052508\n",
      "  validation accuracy:\t\t98.70 %\n",
      "Epoch 419 of 500 took 1.314s\n",
      "  training loss:\t\t0.018970\n",
      "  validation loss:\t\t0.052480\n",
      "  validation accuracy:\t\t98.74 %\n",
      "Epoch 420 of 500 took 1.296s\n",
      "  training loss:\t\t0.020079\n",
      "  validation loss:\t\t0.052256\n",
      "  validation accuracy:\t\t98.72 %\n",
      "Epoch 421 of 500 took 1.309s\n",
      "  training loss:\t\t0.020378\n",
      "  validation loss:\t\t0.052438\n",
      "  validation accuracy:\t\t98.70 %\n",
      "Epoch 422 of 500 took 1.291s\n",
      "  training loss:\t\t0.020362\n",
      "  validation loss:\t\t0.051821\n",
      "  validation accuracy:\t\t98.75 %\n",
      "Epoch 423 of 500 took 1.294s\n",
      "  training loss:\t\t0.021253\n",
      "  validation loss:\t\t0.051774\n",
      "  validation accuracy:\t\t98.71 %\n",
      "Epoch 424 of 500 took 1.286s\n",
      "  training loss:\t\t0.021339\n",
      "  validation loss:\t\t0.051030\n",
      "  validation accuracy:\t\t98.74 %\n",
      "Epoch 425 of 500 took 1.302s\n",
      "  training loss:\t\t0.021469\n",
      "  validation loss:\t\t0.051658\n",
      "  validation accuracy:\t\t98.71 %\n",
      "Epoch 426 of 500 took 1.293s\n",
      "  training loss:\t\t0.020163\n",
      "  validation loss:\t\t0.051729\n",
      "  validation accuracy:\t\t98.74 %\n",
      "Epoch 427 of 500 took 1.308s\n",
      "  training loss:\t\t0.019133\n",
      "  validation loss:\t\t0.051836\n",
      "  validation accuracy:\t\t98.73 %\n",
      "Epoch 428 of 500 took 1.293s\n",
      "  training loss:\t\t0.022858\n",
      "  validation loss:\t\t0.052486\n",
      "  validation accuracy:\t\t98.71 %\n",
      "Epoch 429 of 500 took 1.301s\n",
      "  training loss:\t\t0.021643\n",
      "  validation loss:\t\t0.052745\n",
      "  validation accuracy:\t\t98.71 %\n",
      "Epoch 430 of 500 took 1.292s\n",
      "  training loss:\t\t0.020621\n",
      "  validation loss:\t\t0.053262\n",
      "  validation accuracy:\t\t98.71 %\n",
      "Epoch 431 of 500 took 1.284s\n",
      "  training loss:\t\t0.020732\n",
      "  validation loss:\t\t0.053022\n",
      "  validation accuracy:\t\t98.68 %\n",
      "Epoch 432 of 500 took 1.293s\n",
      "  training loss:\t\t0.018951\n",
      "  validation loss:\t\t0.053523\n",
      "  validation accuracy:\t\t98.66 %\n",
      "Epoch 433 of 500 took 1.314s\n",
      "  training loss:\t\t0.021740\n",
      "  validation loss:\t\t0.053559\n",
      "  validation accuracy:\t\t98.65 %\n",
      "Epoch 434 of 500 took 1.295s\n",
      "  training loss:\t\t0.019282\n",
      "  validation loss:\t\t0.052785\n",
      "  validation accuracy:\t\t98.73 %\n",
      "Epoch 435 of 500 took 1.308s\n",
      "  training loss:\t\t0.019009\n",
      "  validation loss:\t\t0.053832\n",
      "  validation accuracy:\t\t98.68 %\n",
      "Epoch 436 of 500 took 1.312s\n",
      "  training loss:\t\t0.019052\n",
      "  validation loss:\t\t0.052905\n",
      "  validation accuracy:\t\t98.70 %\n",
      "Epoch 437 of 500 took 1.299s\n",
      "  training loss:\t\t0.019640\n",
      "  validation loss:\t\t0.051923\n",
      "  validation accuracy:\t\t98.75 %\n",
      "Epoch 438 of 500 took 1.296s\n",
      "  training loss:\t\t0.020176\n",
      "  validation loss:\t\t0.053090\n",
      "  validation accuracy:\t\t98.67 %\n",
      "Epoch 439 of 500 took 1.299s\n",
      "  training loss:\t\t0.019842\n",
      "  validation loss:\t\t0.052792\n",
      "  validation accuracy:\t\t98.73 %\n",
      "Epoch 440 of 500 took 1.299s\n",
      "  training loss:\t\t0.018291\n",
      "  validation loss:\t\t0.052758\n",
      "  validation accuracy:\t\t98.73 %\n",
      "Epoch 441 of 500 took 1.288s\n",
      "  training loss:\t\t0.020068\n",
      "  validation loss:\t\t0.053238\n",
      "  validation accuracy:\t\t98.79 %\n",
      "Epoch 442 of 500 took 1.304s\n",
      "  training loss:\t\t0.019138\n",
      "  validation loss:\t\t0.053337\n",
      "  validation accuracy:\t\t98.75 %\n",
      "Epoch 443 of 500 took 1.304s\n",
      "  training loss:\t\t0.021082\n",
      "  validation loss:\t\t0.053088\n",
      "  validation accuracy:\t\t98.65 %\n",
      "Epoch 444 of 500 took 1.291s\n",
      "  training loss:\t\t0.019384\n",
      "  validation loss:\t\t0.052031\n",
      "  validation accuracy:\t\t98.71 %\n",
      "Epoch 445 of 500 took 1.304s\n",
      "  training loss:\t\t0.019044\n",
      "  validation loss:\t\t0.053531\n",
      "  validation accuracy:\t\t98.70 %\n",
      "Epoch 446 of 500 took 1.297s\n",
      "  training loss:\t\t0.019789\n",
      "  validation loss:\t\t0.051814\n",
      "  validation accuracy:\t\t98.73 %\n",
      "Epoch 447 of 500 took 1.299s\n",
      "  training loss:\t\t0.020509\n",
      "  validation loss:\t\t0.053025\n",
      "  validation accuracy:\t\t98.68 %\n",
      "Epoch 448 of 500 took 1.282s\n",
      "  training loss:\t\t0.020148\n",
      "  validation loss:\t\t0.052402\n",
      "  validation accuracy:\t\t98.69 %\n",
      "Epoch 449 of 500 took 1.297s\n",
      "  training loss:\t\t0.018708\n",
      "  validation loss:\t\t0.053056\n",
      "  validation accuracy:\t\t98.65 %\n",
      "Epoch 450 of 500 took 1.309s\n",
      "  training loss:\t\t0.019850\n",
      "  validation loss:\t\t0.052274\n",
      "  validation accuracy:\t\t98.69 %\n",
      "Epoch 451 of 500 took 1.286s\n",
      "  training loss:\t\t0.019154\n",
      "  validation loss:\t\t0.053943\n",
      "  validation accuracy:\t\t98.65 %\n",
      "Epoch 452 of 500 took 1.307s\n",
      "  training loss:\t\t0.019450\n",
      "  validation loss:\t\t0.055770\n",
      "  validation accuracy:\t\t98.60 %\n",
      "Epoch 453 of 500 took 1.304s\n",
      "  training loss:\t\t0.018198\n",
      "  validation loss:\t\t0.054184\n",
      "  validation accuracy:\t\t98.65 %\n",
      "Epoch 454 of 500 took 1.297s\n",
      "  training loss:\t\t0.020433\n",
      "  validation loss:\t\t0.052937\n",
      "  validation accuracy:\t\t98.65 %\n",
      "Epoch 455 of 500 took 1.295s\n",
      "  training loss:\t\t0.018259\n",
      "  validation loss:\t\t0.053396\n",
      "  validation accuracy:\t\t98.67 %\n",
      "Epoch 456 of 500 took 1.279s\n",
      "  training loss:\t\t0.019296\n",
      "  validation loss:\t\t0.053603\n",
      "  validation accuracy:\t\t98.63 %\n",
      "Epoch 457 of 500 took 1.292s\n",
      "  training loss:\t\t0.019015\n",
      "  validation loss:\t\t0.053917\n",
      "  validation accuracy:\t\t98.70 %\n",
      "Epoch 458 of 500 took 1.288s\n",
      "  training loss:\t\t0.018896\n",
      "  validation loss:\t\t0.052774\n",
      "  validation accuracy:\t\t98.74 %\n",
      "Epoch 459 of 500 took 1.308s\n",
      "  training loss:\t\t0.017396\n",
      "  validation loss:\t\t0.052503\n",
      "  validation accuracy:\t\t98.73 %\n",
      "Epoch 460 of 500 took 1.295s\n",
      "  training loss:\t\t0.020128\n",
      "  validation loss:\t\t0.052295\n",
      "  validation accuracy:\t\t98.67 %\n",
      "Epoch 461 of 500 took 1.312s\n",
      "  training loss:\t\t0.019776\n",
      "  validation loss:\t\t0.053176\n",
      "  validation accuracy:\t\t98.67 %\n",
      "Epoch 462 of 500 took 1.317s\n",
      "  training loss:\t\t0.017831\n",
      "  validation loss:\t\t0.053177\n",
      "  validation accuracy:\t\t98.74 %\n",
      "Epoch 463 of 500 took 1.315s\n",
      "  training loss:\t\t0.018748\n",
      "  validation loss:\t\t0.053169\n",
      "  validation accuracy:\t\t98.72 %\n",
      "Epoch 464 of 500 took 1.322s\n",
      "  training loss:\t\t0.018383\n",
      "  validation loss:\t\t0.052970\n",
      "  validation accuracy:\t\t98.69 %\n",
      "Epoch 465 of 500 took 1.294s\n",
      "  training loss:\t\t0.018609\n",
      "  validation loss:\t\t0.052960\n",
      "  validation accuracy:\t\t98.72 %\n",
      "Epoch 466 of 500 took 1.298s\n",
      "  training loss:\t\t0.019610\n",
      "  validation loss:\t\t0.053516\n",
      "  validation accuracy:\t\t98.70 %\n",
      "Epoch 467 of 500 took 1.314s\n",
      "  training loss:\t\t0.018560\n",
      "  validation loss:\t\t0.053931\n",
      "  validation accuracy:\t\t98.66 %\n",
      "Epoch 468 of 500 took 1.290s\n",
      "  training loss:\t\t0.018331\n",
      "  validation loss:\t\t0.053052\n",
      "  validation accuracy:\t\t98.69 %\n",
      "Epoch 469 of 500 took 1.305s\n",
      "  training loss:\t\t0.017712\n",
      "  validation loss:\t\t0.054502\n",
      "  validation accuracy:\t\t98.70 %\n",
      "Epoch 470 of 500 took 1.282s\n",
      "  training loss:\t\t0.018563\n",
      "  validation loss:\t\t0.053220\n",
      "  validation accuracy:\t\t98.67 %\n",
      "Epoch 471 of 500 took 1.285s\n",
      "  training loss:\t\t0.019305\n",
      "  validation loss:\t\t0.052218\n",
      "  validation accuracy:\t\t98.76 %\n",
      "Epoch 472 of 500 took 1.286s\n",
      "  training loss:\t\t0.020043\n",
      "  validation loss:\t\t0.051622\n",
      "  validation accuracy:\t\t98.72 %\n",
      "Epoch 473 of 500 took 1.302s\n",
      "  training loss:\t\t0.020089\n",
      "  validation loss:\t\t0.052172\n",
      "  validation accuracy:\t\t98.73 %\n",
      "Epoch 474 of 500 took 1.297s\n",
      "  training loss:\t\t0.019021\n",
      "  validation loss:\t\t0.052944\n",
      "  validation accuracy:\t\t98.69 %\n",
      "Epoch 475 of 500 took 1.286s\n",
      "  training loss:\t\t0.017811\n",
      "  validation loss:\t\t0.053110\n",
      "  validation accuracy:\t\t98.68 %\n",
      "Epoch 476 of 500 took 1.278s\n",
      "  training loss:\t\t0.018298\n",
      "  validation loss:\t\t0.053159\n",
      "  validation accuracy:\t\t98.64 %\n",
      "Epoch 477 of 500 took 1.300s\n",
      "  training loss:\t\t0.018107\n",
      "  validation loss:\t\t0.053638\n",
      "  validation accuracy:\t\t98.66 %\n",
      "Epoch 478 of 500 took 1.290s\n",
      "  training loss:\t\t0.017800\n",
      "  validation loss:\t\t0.052699\n",
      "  validation accuracy:\t\t98.71 %\n",
      "Epoch 479 of 500 took 1.297s\n",
      "  training loss:\t\t0.016265\n",
      "  validation loss:\t\t0.053595\n",
      "  validation accuracy:\t\t98.66 %\n",
      "Epoch 480 of 500 took 1.290s\n",
      "  training loss:\t\t0.017577\n",
      "  validation loss:\t\t0.053459\n",
      "  validation accuracy:\t\t98.66 %\n",
      "Epoch 481 of 500 took 1.298s\n",
      "  training loss:\t\t0.019115\n",
      "  validation loss:\t\t0.053324\n",
      "  validation accuracy:\t\t98.67 %\n",
      "Epoch 482 of 500 took 1.304s\n",
      "  training loss:\t\t0.018059\n",
      "  validation loss:\t\t0.053542\n",
      "  validation accuracy:\t\t98.74 %\n",
      "Epoch 483 of 500 took 1.289s\n",
      "  training loss:\t\t0.018229\n",
      "  validation loss:\t\t0.052697\n",
      "  validation accuracy:\t\t98.69 %\n",
      "Epoch 484 of 500 took 1.301s\n",
      "  training loss:\t\t0.018599\n",
      "  validation loss:\t\t0.052973\n",
      "  validation accuracy:\t\t98.72 %\n",
      "Epoch 485 of 500 took 1.307s\n",
      "  training loss:\t\t0.017529\n",
      "  validation loss:\t\t0.054032\n",
      "  validation accuracy:\t\t98.64 %\n",
      "Epoch 486 of 500 took 1.304s\n",
      "  training loss:\t\t0.018793\n",
      "  validation loss:\t\t0.053236\n",
      "  validation accuracy:\t\t98.66 %\n",
      "Epoch 487 of 500 took 1.300s\n",
      "  training loss:\t\t0.018780\n",
      "  validation loss:\t\t0.053592\n",
      "  validation accuracy:\t\t98.71 %\n",
      "Epoch 488 of 500 took 1.287s\n",
      "  training loss:\t\t0.018509\n",
      "  validation loss:\t\t0.053824\n",
      "  validation accuracy:\t\t98.69 %\n",
      "Epoch 489 of 500 took 1.425s\n",
      "  training loss:\t\t0.018028\n",
      "  validation loss:\t\t0.053666\n",
      "  validation accuracy:\t\t98.68 %\n",
      "Epoch 490 of 500 took 1.304s\n",
      "  training loss:\t\t0.018675\n",
      "  validation loss:\t\t0.053501\n",
      "  validation accuracy:\t\t98.68 %\n",
      "Epoch 491 of 500 took 1.303s\n",
      "  training loss:\t\t0.018278\n",
      "  validation loss:\t\t0.052241\n",
      "  validation accuracy:\t\t98.72 %\n",
      "Epoch 492 of 500 took 1.297s\n",
      "  training loss:\t\t0.018158\n",
      "  validation loss:\t\t0.053972\n",
      "  validation accuracy:\t\t98.63 %\n",
      "Epoch 493 of 500 took 1.286s\n",
      "  training loss:\t\t0.016984\n",
      "  validation loss:\t\t0.053767\n",
      "  validation accuracy:\t\t98.65 %\n",
      "Epoch 494 of 500 took 1.319s\n",
      "  training loss:\t\t0.017373\n",
      "  validation loss:\t\t0.054487\n",
      "  validation accuracy:\t\t98.68 %\n",
      "Epoch 495 of 500 took 1.295s\n",
      "  training loss:\t\t0.018227\n",
      "  validation loss:\t\t0.053968\n",
      "  validation accuracy:\t\t98.67 %\n",
      "Epoch 496 of 500 took 1.317s\n",
      "  training loss:\t\t0.018237\n",
      "  validation loss:\t\t0.054168\n",
      "  validation accuracy:\t\t98.63 %\n",
      "Epoch 497 of 500 took 1.284s\n",
      "  training loss:\t\t0.017950\n",
      "  validation loss:\t\t0.053937\n",
      "  validation accuracy:\t\t98.70 %\n",
      "Epoch 498 of 500 took 1.286s\n",
      "  training loss:\t\t0.017750\n",
      "  validation loss:\t\t0.054001\n",
      "  validation accuracy:\t\t98.68 %\n",
      "Epoch 499 of 500 took 1.287s\n",
      "  training loss:\t\t0.018166\n",
      "  validation loss:\t\t0.053511\n",
      "  validation accuracy:\t\t98.71 %\n",
      "Epoch 500 of 500 took 1.307s\n",
      "  training loss:\t\t0.017634\n",
      "  validation loss:\t\t0.051857\n",
      "  validation accuracy:\t\t98.75 %\n",
      "Final results:\n",
      "  test loss:\t\t\t0.044471\n",
      "  test accuracy:\t\t98.77 %\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
